{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWrxxeDh5JhxhoitzOOsCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning-Fastai/blob/main/Chapters%20Notebooks/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMNhpmiGmiYd"
      },
      "source": [
        "# **Chapter - 5 (Fastai Book)**\n",
        "\n",
        "# Image Classification \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjihaF8XoJkZ"
      },
      "source": [
        "# Run once\n",
        "\n",
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vWe5DQGnFOX",
        "outputId": "54320876-4af3-40d1-ba06-e8d01b6b9ff4"
      },
      "source": [
        "# Certain utils\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "\n",
        "# Needed packages\n",
        "\n",
        "from fastai import *\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77KZX1rKniSs"
      },
      "source": [
        "As in previous lectures we peeked under the hood, but the important thing is to make our model perform really well we have to keep an eye out for lot of details. \n",
        "\n",
        "This process requires being able to look inside the neural network as it trains and as it make predictions, find possible problems and know how to fix them\n",
        "\n",
        "From now on will dive deep into mechanics of deep learning, things like: \n",
        "- Architecture of computer vision model , NLP , tabular model.\n",
        "- how to create arch that matches the needs of our particular domain.\n",
        "- how to get the best possible results from the training process.\n",
        "- and how to make things faster\n",
        "- what changes we gotta make as the datasets change etc...\n",
        "\n",
        "Going to make the basic application looked earlier in the Chapter 1, but will do 2 things to that : \n",
        "\n",
        "- Make them better\n",
        "- Apply them to a wider variety of types of data\n",
        "\n",
        "Well to work out these 2 things, we gotta learn the pieces of deep learning puzzle, which includes:\n",
        "\n",
        "- Types of layers\n",
        "- Regularization methods\n",
        "- optimizers\n",
        "- how to put layers together into architectures\n",
        "- labelling techniques etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COb6Cq9Bs711"
      },
      "source": [
        "## **From Dogs and Cats to Pet Breeds**\n",
        "\n",
        "But in Chapter 1 we discussed about Dog v/s Cat which was easy enough to work on, but it seems this `PETs` dataset is more complex than what we did in the Chapter 1. Where now will dive deep to figure out what breed of pet is shown in each image.\n",
        "\n",
        "In practical things will be more different like, \n",
        "\n",
        "- we start with a dataset we know nothing about\n",
        "- figure out how it is put together\n",
        "- how to extract the data we needed from it\n",
        "- and what the data looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-tA_SSlxuqTD",
        "outputId": "fc56aa40-0aae-4135-d108-4392c6b3eec5"
      },
      "source": [
        "# Getting the data \n",
        "path = untar_data(URLs.PETS)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dEsbaKkvAml"
      },
      "source": [
        "To get those breeds out of the data, firstly we gotta understand how this data is laid out. Such details of data layout are a vital piece of deep learning puzzle. \n",
        "\n",
        "Data is usually provided in one of these 2 ways: \n",
        "\n",
        "- Individual files representing items of data, such as text docs or images which are **organized into folders or with filenames** representing info about those items.\n",
        "- A table of data (e.g CSV format) in which **each row is an item** and may include **filenames providing connections data in the table and data in other formats**, such as text or images.\n",
        "\n",
        "But there are exceptions to these above rules, in domains like genomic, where there will be a **binary database or even network streams** but overall the vast majority of datasets will be in the **combinations of the above 2 rules**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63xIXeuzwgh1",
        "outputId": "9b8be1ed-511e-4585-be04-52ea40e6242f"
      },
      "source": [
        "# To see what's in our dataset \n",
        "\n",
        "path.ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/oxford-iiit-pet/annotations'),Path('/root/.fastai/data/oxford-iiit-pet/images')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLACpM7fwlf9"
      },
      "source": [
        "Well this dataset provides us with `images` and `annotations`, the **annotation library** --> contains information where the pets are. \n",
        "\n",
        "\n",
        "* **classification** --> what the pets are \n",
        "* **localization** --> where the pets are \n",
        "\n",
        "In this chapter will work on **classification** and ignore the annotations directory for now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDJU9wlt5ksU",
        "outputId": "df355cea-224d-45a7-bc7e-fc1b4a03c3a2"
      },
      "source": [
        "# Looking into the image directory \n",
        "\n",
        "(path /'images').ls()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_31.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_149.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Russian_Blue_221.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/american_bulldog_74.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_64.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_71.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/chihuahua_141.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/english_setter_21.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_119.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/beagle_175.jpg')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihsnS6uv5otS"
      },
      "source": [
        "Most functions and methods in **fastai** that returns a collection (like above) use a *class* called `L` .\n",
        "\n",
        "Yet this is an enhanced version of the ordinary Python `list` type, for instance when we display a object of this class in a notebook. It appears in the format, \n",
        "\n",
        "- first thing that is shown is the number of items in the collection, prefixed with `#`. \n",
        "- certain outputs of this list is suffixed with ellipsis, means only first few items are displayed. As we don't want to to see more than 7000 filenames on our screens.\n",
        "--- \n",
        "\n",
        "If we examine these filenames, we can see how they are structured. Each filenames contains the pet breed, then an underscore **(_)** , a **number** and finally the **file extension** (png , jpg etc..).\n",
        "\n",
        "Now we gotta make a piece of code that extracts the breed from a single **Path**. Lets pick one of the filenames and play with it to find more.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QSLNAGo7Gmm",
        "outputId": "54d789a6-fe84-4c0d-c549-aed086319826"
      },
      "source": [
        "# Testing out how a file name looks like \n",
        "\n",
        "fname = (path / 'images').ls()[0]\n",
        "fname"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_31.jpg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FugPsuek9b34"
      },
      "source": [
        "Most powerful and flexible way to extract information from a string like this is to use a **regular expression**, also known as **regex**.\n",
        "\n",
        "A regular expression is a special string, written in the regular expression language. Which specifies a general rule for deciding whether another **string passes a test** (matche or not) and also **parsing a particular part or parts out of that string**. In our case we need a regular expression that extracts the pet breed from the *filename*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAL5r5EC_EV_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}