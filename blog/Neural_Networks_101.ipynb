{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks_101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPq2JisrKhDED7P7kBOSrE6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning-Fastai/blob/main/blog/Neural_Networks_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSo3qeLsxrRr"
      },
      "source": [
        "# Neural Networks 101 Part 2 \n",
        "\n",
        "Hope you guys read the previous part of this blog, where we discussed about the following topics, \n",
        "- When do we call a ‘program’ a machine learning model?\n",
        "- How to convert a traditional program into a machine learning model \n",
        "- SGD steps \n",
        "- What are gradients \n",
        "\n",
        "If you didnt read the previous part, make sure to check it out here [Neural Networks 101 — Part 1](https://medium.com/artificialis/neural-networks-101-88d4b1f5d854) \n",
        "\n",
        "\n",
        "## What we're going to cover? \n",
        "We've played enough with the theory, now its time to get our hands dirty with code. In this we will write pytorch and fastai code in order to represent the 7 steps in code. \n",
        "\n",
        "Also we will use the mnist data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG2k2HENyzJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1254a50-459c-443d-fcdc-90536ea6a2cd"
      },
      "source": [
        "# Installing fastai \n",
        "!pip install fastai --upgrade "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: torch<1.10,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.26)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.62.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0h0BO6aztU6"
      },
      "source": [
        "Before getting started lets get our data and preprocess it for further process. \n",
        "\n",
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhLlR5RM3rgK"
      },
      "source": [
        "# Importing fastai and torch \n",
        "import torch \n",
        "from fastai import * \n",
        "from fastai.vision.all import * "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GuwAxDj36Cn"
      },
      "source": [
        "## Calculating Gradients with pytorch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga-CnNZn4686"
      },
      "source": [
        "# Creating a tensor (that will keep track of the gradients of the value)\n",
        "xt = tensor(8.).requires_grad_()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6At2wZT5I6Q",
        "outputId": "5d00e16b-6de5-4120-b65d-782ebe949321"
      },
      "source": [
        "# Our sample loss function \n",
        "def f(x):\n",
        "  return x**2\n",
        "\n",
        "# Performing some computations with the variable xt \n",
        "yt = f(xt)\n",
        "print(yt)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(64., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irgUrz85c0s"
      },
      "source": [
        "# Now we're telling Pytorch to calculate the gradients \n",
        "# This will give us the gradients \n",
        "\n",
        "yt.backward() "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNjn6Iu17c7H",
        "outputId": "e24ef4dc-77b6-41a9-905e-3736b9098452"
      },
      "source": [
        "# Now looking at the gradients calculated on our variable\n",
        "xt.grad"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBw2m0kp-xii"
      },
      "source": [
        "> **Note** : The graidents will tell us only the slope of our function, they don't really say how far we should adjust the parameters.\n",
        "\n",
        "\n",
        "So how to tell our parameters the way they should move in order to minimize the loss? \n",
        "\n",
        "**Learning Rate** \n",
        "\n",
        "- The gradients tells us the directions but not the magnitude of the direction (i.e the step we have to take).\n",
        "- This is where our **learning rate** helps, it tells us how large each step should be. Or in other words it gives us the scale of how much we should trust the gradients and step in the direction of that gradient.\n",
        "\n",
        "So we will multiply gradient by a small number (learning rate) to step the weights. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fN0DnID-7Mb"
      },
      "source": [
        "## And End-to-End SGD Example \n",
        "\n",
        "Here we will code out the entire 7 steps that we saw in the blog! \n",
        "\n",
        "Lets re-visit the 7 steps, \n",
        "- **Step 1**: Find a way to initialize random weights.\n",
        "- **Step 2**: And for each image, use these weights to predict whether it appears to be a `3` or a `7`.\n",
        "- **Step 3**: Based on the above predictions calculate how good the model is. This is where we introduce the term called loss function.\n",
        "- **Step 4**: Calculate the gradient, which plays a crucial role in weight assignment. It will tell us how to change the weights so that our loss would change.\n",
        "- **Step 5**: Step the weights, that is change the weights based on the gradients calculated.\n",
        "- **Step 6**: Go back to Step 2 and repeat the process.\n",
        "- **Step 7**: Iterate until we decide to stop the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmdaCqrkBmuO"
      },
      "source": [
        "# Creating dummy data for our example \n",
        "# Time \n",
        "time = torch.arange(0 , 20).float()\n",
        "\n",
        "# Calculating the speed for the time step \n",
        "speed = torch.randn(20)*3 + 0.75*(time -9.5)**2 + 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzpfWnJZCjeG"
      },
      "source": [
        "We know the fact while calculating gradients we need a function that takes in inputs and give us the predictions. Further with the prediction and the targets we compute the gradients and so on... \n",
        "\n",
        "Now lets create that function which does the computation. This function takes in the input and random initialized parameters. \n",
        "\n",
        "```\n",
        "x -> inputs   |\n",
        "w -> weights  |   f = x * w (params multiplied with inputs)\n",
        "f -> function |\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5SgxaHCznG"
      },
      "source": [
        "# Writing the function which multiplies our input and the parameter \n",
        "def func(t , params):\n",
        "  '''\n",
        "  Takes in our time (input) and the params (parameters)\n",
        "\n",
        "  Compute the equation of form --> a*(t**2) + (b*t) + c\n",
        "  '''\n",
        "  # Unpacking the parameters \n",
        "  a , b , c = params \n",
        "  return a*(t**2) + (b*t) + c"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLYB8evFVw9"
      },
      "source": [
        "Perfect! Whats yet left? \n",
        "\n",
        "Well our loss function, we found a way to get our predictions and now all we need is a loss function that will let us know how bad our predictions are, so we can improve it by minimizing the loss. \n",
        "\n",
        "Lets get em! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMxTXVd7Fo4g"
      },
      "source": [
        "# Defining our loss function \n",
        "def mse(preds , targs):\n",
        "  return ((preds - targs)**2).mean()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Y1Px5VHXBa"
      },
      "source": [
        "Oops... Did we forget something? \n",
        "\n",
        "Well think about it... \n",
        "\n",
        "We got our function , loss function and what else is left? \n",
        "\n",
        "Our parameters.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yx4KYMuNYVj",
        "outputId": "afd2c293-564f-4270-8e40-52b5aa2a4490"
      },
      "source": [
        "# Initialize the parameters (random)\n",
        "params = torch.randn(3).requires_grad_()\n",
        "params "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9288, -0.7495, -1.4803], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ufc5xkZNd2F",
        "outputId": "22b01a10-8359-4b82-8f44-e7e9733bcc98"
      },
      "source": [
        "# Lets calculate our predictions \n",
        "preds = func(time , params)\n",
        "preds"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -1.4803,   -3.1586,   -6.6945,  -12.0878,  -19.3387,  -28.4471,\n",
              "         -39.4130,  -52.2364,  -66.9174,  -83.4559, -101.8519, -122.1055,\n",
              "        -144.2165, -168.1851, -194.0112, -221.6949, -251.2361, -282.6347,\n",
              "        -315.8910, -351.0047], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyWr4l9qOrAW"
      },
      "source": [
        "# Now the next step would be the loss function \n",
        "loss = mse(preds , speed)\n",
        "\n",
        "# Calculating the gradients from the loss funtion \n",
        "loss.backward() "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olhKTROCU9Cv",
        "outputId": "f7592e86-3388-43ec-9ce9-ac84c961cdcf"
      },
      "source": [
        "# We will get the gradients for a, b and c \n",
        "params.grad "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-62920.3516,  -4047.7341,   -298.2272])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngatz6QOVAGQ"
      },
      "source": [
        "# Now lets multiply learning rate with gradients to step up the weights \n",
        "lr = 1e-3 \n",
        "\n",
        "params.data -= lr * params.grad.data \n",
        "\n",
        "# Setting params to None \n",
        "params.grad = None "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkf71vxWVXUE"
      },
      "source": [
        "Perfect so far! Now lets put back everything in one stand alone function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJRu23AIOgPc"
      },
      "source": [
        "# Putting everything into a function "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0RwAdMjOkdH"
      },
      "source": [
        "Lets re-visit the 7 steps, \n",
        "- **Step 1**: Find a way to initialize random weights.\n",
        "- **Step 2**: And for each image, use these weights to predict whether it appears to be a `3` or a `7`.\n",
        "- **Step 3**: Based on the above predictions calculate how good the model is. This is where we introduce the term called loss function.\n",
        "- **Step 4**: Calculate the gradient, which plays a crucial role in weight assignment. It will tell us how to change the weights so that our loss would change.\n",
        "- **Step 5**: Step the weights, that is change the weights based on the gradients calculated.\n",
        "- **Step 6**: Go back to Step 2 and repeat the process.\n",
        "- **Step 7**: Iterate until we decide to stop the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jztY2N9dOrij"
      },
      "source": [
        "def end_to_end(prn = True , lr = 1e-3):\n",
        "  '''\n",
        "  Takes in the parameters as their arguments, computes the seven steps that makes a traditional program into a machine learning model\n",
        "  '''\n",
        "  # Step 1: Find a way to initialize the weights \n",
        "  params = torch.randn(3).requires_grad_()\n",
        "\n",
        "  # Step 2: Calculating the predictions \n",
        "  preds = func(time , params)\n",
        "\n",
        "  # Step 3: Now time to calculate the loss \n",
        "  loss = mse(preds , speed)\n",
        "\n",
        "  # Step 4: Initiating back propagation and time for calculating the gradients to improve our params \n",
        "  loss.backward() \n",
        "\n",
        "  # Step 5: Step the weights with learning rate (so we get a direction on how to move our params)\n",
        "  params.data -= lr * params.grad.data \n",
        "  # Set gradients back to none for the next iteration, so the old values wont add up with existing one \n",
        "  params.grad = None \n",
        "  \n",
        "  # Step 6 and 7 depends on the iteration we are running this function for \n",
        "  if prn: \n",
        "    print(loss.item())\n",
        "  return preds\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXrqW70qQnUi",
        "outputId": "554f73b1-5ad3-4c40-ee80-c86433a0ea7a"
      },
      "source": [
        "# Now by iterating for N number of times we get the Step 6 and 7\n",
        "for i in range(10):\n",
        "  end_to_end()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1469.0186767578125\n",
            "9179.2958984375\n",
            "44846.9765625\n",
            "13225.7158203125\n",
            "7813.4716796875\n",
            "11886.7919921875\n",
            "83430.59375\n",
            "1729.3951416015625\n",
            "49318.3046875\n",
            "91888.6015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS0BX09wQyaW"
      },
      "source": [
        "Alright enough playing with a dummy data, now lets apply the same principle for our mnist sample data. Also we will be using Pytorch and Fastai functionality to speed up the process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO9YI3mRcdQ7"
      },
      "source": [
        "## Wrapping up with Fastai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvSefOVhNM5w"
      },
      "source": [
        "# Loading the mnist data and untar it\n",
        "data_path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2lvBSr5Y7_B",
        "outputId": "4802dfbc-0fc3-4b98-82fb-6cd3031164b6"
      },
      "source": [
        "# Getting thhe filenames because the Datasets accepts a list of filenames \n",
        "item_fns = get_image_files(data_path)\n",
        "\n",
        "# Looking inside \n",
        "item_fns[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('/root/.fastai/data/mnist_png/testing/8/5940.png'),Path('/root/.fastai/data/mnist_png/testing/8/3949.png'),Path('/root/.fastai/data/mnist_png/testing/8/4626.png'),Path('/root/.fastai/data/mnist_png/testing/8/7378.png'),Path('/root/.fastai/data/mnist_png/testing/8/2004.png'),Path('/root/.fastai/data/mnist_png/testing/8/4362.png'),Path('/root/.fastai/data/mnist_png/testing/8/3197.png'),Path('/root/.fastai/data/mnist_png/testing/8/543.png'),Path('/root/.fastai/data/mnist_png/testing/8/8015.png'),Path('/root/.fastai/data/mnist_png/testing/8/7428.png')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00RXkiRgZZYS"
      },
      "source": [
        "# Splitting our data using the GrandParentSplitter --> looks for train and valid/test folders \n",
        "splits = GrandparentSplitter(train_name= 'training' , valid_name= 'testing')\n",
        "splits = splits(item_fns)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRR02Aidjb1"
      },
      "source": [
        "The `splits` itself doesnt do the splitting, we've just creates an instance of the objeect, where passing the items later will give us the train and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "rXHWPhxIdwmE",
        "outputId": "24fd7e83-b3e4-407d-ffd3-8b48ea86af01"
      },
      "source": [
        "# How does the filename looks like? \n",
        "im = PILImageBW.create(item_fns[5]) # 5th filename \n",
        "im.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ba0f65450>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi6VTGy7gChI"
      },
      "source": [
        "Breaking down the above function: \n",
        "- `PILImageBW` -> creates a PIL image (accepts a filepath)\n",
        "- `.create` -> takes care of the preprocessing before going into the model. This is applicable for both X and y, more like a custom implementation for the various inputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXCv5uVFgYTL"
      },
      "source": [
        "Great now lets build a Datasets which expects , \n",
        "- the items we want to use \n",
        "- the transforms (how the inputs and outputs should be constructed and spits out)\n",
        "- the type of split (train and test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC3r59bpiKV3"
      },
      "source": [
        "dsets  = Datasets(items = item_fns , \n",
        "                  tfms = [[PILImageBW.create] , [parent_label , Categorize]] , \n",
        "                  splits = splits)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krJi_XZ1i1Ok"
      },
      "source": [
        "We got our filenames into images, but for a machine learning model we have to convert our images into tensors (numerical representation) and make it easy for our model to learn patterns on it. \n",
        "\n",
        "We need to give ourselves some transforms on the data! These will need to:\n",
        "\n",
        "- Ensure our images are all the same size\n",
        "- Make sure our output are the tensor our models are wanting\n",
        "- Give some image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeHLI1uljoVD"
      },
      "source": [
        "# Creating transforms for our data by hand (left to right)\n",
        "tfms = [ToTensor() , CropPad(size = 34 , pad_mode = PadMode.Zeros) , RandomCrop(size = 28)]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjEzg8l1kCUJ"
      },
      "source": [
        "We need one more thing atlast, that is transforms applied during the GPU instance or in other words transforms applied for every batches. \n",
        "\n",
        "We have to load our **Datasets** into a `DataLoaders` so it will help us to batch our data and sends batch of our whole data during the training time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH9kkPFZlJMI"
      },
      "source": [
        "# Creating the batch transforms \n",
        "gpu_tfms = [IntToFloatTensor() , Normalize()]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kER9xyK-cLd1"
      },
      "source": [
        "Before the next step, we have to make our data into batches. But why do we need our data in batches? \n",
        "\n",
        "Well the importatn reason for having mini-batches is it could run on GPU, so the computations takes places even more faster. \n",
        "\n",
        "Also batching prevents the bias during training and helps the trainig converge faster. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "211x1NrQki3o",
        "outputId": "ac497452-bc85-4a7d-da9c-5128a7ac802b"
      },
      "source": [
        "# Building our dataloaders \n",
        "dls = dsets.dataloaders(bs = 128 , after_item= tfms , after_batch= gpu_tfms)\n",
        "\n",
        "# Visualizing the random batch images with transforms \n",
        "dls.show_batch()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7_m2kFXXwY6"
      },
      "source": [
        "def conv2(ni , nf):\n",
        "  return ConvLayer(ni , nf , stride = 2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaJrUSUhlXeK"
      },
      "source": [
        "# Constructing a simple model \n",
        "model = nn.Sequential(\n",
        "      conv2(1 , 8), \n",
        "      conv2(8 ,16), \n",
        "      conv2(16 , 32), \n",
        "      conv2(32 , 16), \n",
        "      conv2(16 , 10), \n",
        "      Flatten()\n",
        ")\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "AfJEvcM1XHXi",
        "outputId": "49e1e5d5-5c1c-434e-fc6b-84675d6954cc"
      },
      "source": [
        "# Creting a learner \n",
        "learn = Learner(dls , model , loss_func= CrossEntropyLossFlat() , metrics = accuracy)\n",
        "\n",
        "# Fitting the model for 3 epochs \n",
        "learn.fit_one_cycle(3 , lr_max = 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/3 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='57' class='' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      12.18% [57/468 00:12<01:31 2.1935]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOunEOzCXghR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}