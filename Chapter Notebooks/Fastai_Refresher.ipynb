{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai_Refresher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOARxHR8X/V6u6G9YD2TaPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning-Fastai/blob/main/Chapter%20Notebooks/Fastai_Refresher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uuMuqBjhkvF"
      },
      "source": [
        "This notebooks will cover 4 chapters of the Fastai lectures. After 2 months of break and now I decided I have to go back and finish this book and take proper notes and use my skills in competition. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDh4f6RXrvU3",
        "outputId": "37775faf-f4eb-464e-8934-fc6cd696276e"
      },
      "source": [
        "# Installing fastai \n",
        "!pip install fastai --upgrade "
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: fastai in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.20)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.10,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.2->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.10,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ4qLqI8rzdk"
      },
      "source": [
        "# Importing the needed libs \n",
        "from fastai import * \n",
        "from fastai.vision.all import *"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niUdsVcm5U0f"
      },
      "source": [
        "# Under the hood: Training a Digit Training Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjSh-6NqtJeK",
        "outputId": "3cd34ea8-8ee0-4a70-8d89-72709d0387d8"
      },
      "source": [
        "# Reading the data\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "path.ls()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/root/.fastai/data/mnist_sample/labels.csv'),Path('/root/.fastai/data/mnist_sample/train'),Path('/root/.fastai/data/mnist_sample/valid')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4VF8J3dr49f",
        "outputId": "8d15ee54-5db8-47e5-b36b-7f0a8d5ef7f0"
      },
      "source": [
        "# Putting into sep variable of 3 and 7 \n",
        "threes = (path / 'train' / '3').ls().sorted()\n",
        "sevens = (path / 'train' / '7').ls().sorted()\n",
        "\n",
        "threes[:5] , sevens[:5]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((#5) [Path('/root/.fastai/data/mnist_sample/train/3/10.png'),Path('/root/.fastai/data/mnist_sample/train/3/10000.png'),Path('/root/.fastai/data/mnist_sample/train/3/10011.png'),Path('/root/.fastai/data/mnist_sample/train/3/10031.png'),Path('/root/.fastai/data/mnist_sample/train/3/10034.png')],\n",
              " (#5) [Path('/root/.fastai/data/mnist_sample/train/7/10002.png'),Path('/root/.fastai/data/mnist_sample/train/7/1001.png'),Path('/root/.fastai/data/mnist_sample/train/7/10014.png'),Path('/root/.fastai/data/mnist_sample/train/7/10019.png'),Path('/root/.fastai/data/mnist_sample/train/7/10039.png')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ijd622ItD8Z",
        "outputId": "670e4045-5851-4d4c-eafc-eb4de54a8ffe"
      },
      "source": [
        "# Representing in a numpy array \n",
        "img_3 = threes[1]\n",
        "im3 = Image.open(img_3)\n",
        "im3.show()\n",
        "np.array(im3)[4:10 , 4:10] # rows and columns "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,  29],\n",
              "       [  0,   0,   0,  48, 166, 224],\n",
              "       [  0,  93, 244, 249, 253, 187],\n",
              "       [  0, 107, 253, 253, 230,  48],\n",
              "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oPWetkxuc9p"
      },
      "source": [
        "# Stacking all the images in the directory, and converting into tensors\n",
        "\n",
        "seven_tensor = [tensor(Image.open(o)) for o in sevens]\n",
        "three_tensor = [tensor(Image.open(o)) for o in threes]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BPY3H-ItbP0"
      },
      "source": [
        "Calculate the average over all the images of the intensity of the pixel. \n",
        "\n",
        "Our tensors are in integers let's stack them and convert into float by dividing them by 255. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9LFFRX7t5gc",
        "outputId": "663963b3-4ed4-45f2-a4b1-f657ac190de7"
      },
      "source": [
        "stacked_sevens = torch.stack(seven_tensor).float() / 255\n",
        "stacked_threes = torch.stack(three_tensor).float() / 255\n",
        "\n",
        "stacked_sevens[:1]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.2000, 0.8353, 0.9961, 0.9882, 0.9882, 0.9882, 0.9961, 0.9882, 0.9882, 0.9882, 0.9961, 0.9882, 0.9882, 0.9882, 1.0000, 0.9882, 0.3922, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0824, 0.6314, 0.9804, 0.9804, 0.9882, 0.9804, 0.9804, 0.9804, 0.9882, 0.9804, 0.9804, 0.9804, 0.9882, 0.9804, 0.9804, 0.9804, 0.9882, 0.9804, 0.3922, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.2000, 0.9804, 0.9804, 0.9804, 0.9882, 0.7412, 0.7451, 0.9804, 0.9882, 0.9804, 0.9804, 0.9804, 0.9882, 0.9804, 0.9804, 0.9804, 0.9882, 0.7412, 0.1569, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0392, 0.5098, 0.9804, 0.9804, 0.1922, 0.1137, 0.1176, 0.1922, 0.1922, 0.1922, 0.1922, 0.1922, 0.1922, 0.1922, 0.6667, 0.9804, 0.9882, 0.5843, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.5176, 0.9882, 0.9882, 0.9569, 0.4745, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9804, 0.9804, 0.9804, 0.7922, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745, 0.9804, 0.9804, 0.9804, 0.3137, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9882, 0.9804, 0.9804, 0.9804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.8353, 0.9961, 0.9882, 0.9882, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.9804, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.6235, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.9882, 0.9961, 0.9882, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.8667, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.9882, 1.0000, 0.9882, 0.9882, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9804, 0.9882, 0.9804, 0.9804, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.8667, 0.9882, 0.9804, 0.6235, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.8314, 0.1922, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZnOMywsvL1g",
        "outputId": "1f955f15-1696-49ac-cc2c-99297d890a16"
      },
      "source": [
        "# Checking the shape \n",
        "stacked_sevens.shape , stacked_threes.shape"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "7M-FvMESvVb4",
        "outputId": "af40667c-9527-400f-8b41-3db1e35d7c6f"
      },
      "source": [
        "# Finding the ideal 3 by taking average along the 0th dimension\n",
        "mean_3 = stacked_threes.mean(dim = 0)\n",
        "mean_7 = stacked_sevens.mean(dim = 0)\n",
        "show_image(mean_3)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdedc275810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOnUlEQVR4nO2c224kyXGGv4jMrKo+8TizI2vHliBZgA8QfGM/gh/BT+lH8Av4zrAvDBgWLBvGrjQ7szMcsrvrkIfwRVY3udRYwpCzs4bBAIrVJMHsyj8jI+L/I5tiZjzZrekP/QD/1+wJkHv2BMg9ewLknj0Bcs/87/vl3+rf/b9NQf9Q/l4+9PMnD7lnT4DcsydA7tkTIPfs9wbV783kg/HsD9tnoBnfPyCHyYvON6mvVZDD7/QDjloKAEeuVQysYGX+3sp8/7QgfVpA7kz+MHFxCs4hzoFz4P3xZ3hX/+Zwwe0ES4FcICVsvpMzlvN8L7cAWflkwHwaQOQweVdXvmnqpNsWCQFbtFjbUNYNpXWkhacEIXWCOSGHA5Ag2ZACbjLcZPh9RseM20V0Suh+gCliw4BNEaapAvSJgHkcIPOqHlZfvEeCr0A0DbbsKF0gr1vSwhFPPHEhxJWQWyEvoHgoTR3OBCRLBWQAN0G4cfjBaK8Dri+E64D2Edk6ZJwwESwliAnLUL/8EIDc8QppAhI8slhA11I2C9KqZTpviGtHfynEjTBeGGlT0POB5XLki/WO06bnst0TNKMYfQ70OfCq33DVd3z7dg3XgfZ1oLmBxetAsy10rxe43YRebaEfYLuDJFjkUZ7yKA8R5xCn1StCA4sO6xrypiOuPeOZY1oL47kQT4x4kfDryLPzGy4Xe75cXnEZdjwLW4JkWo3sS0M0x3+3F7xZrPmVGlftgtEWlEaRpBQn6BQIAmFsETMYxwpCzo9ykocBIlLBCL5uk9kz8umKvG4YnjeMJ8r+hRA3xvRFJGwmfvrsihfLG362fMMXzTV/HN5y5nZc6p5WMp2U41u8XrVc5SX/fPon/Lp/zj+dfsm3V2u23YLmSine0y0VMXDOoVMEwGICsQdvnQcCokdgDpnDvMNaRwlKDkLxYArmgDlmxuzYxpZv44qMEs2x0Q2v3Z5OI0sZaSQTJLErLYMFHMZCJ5YhctMm9p2RF0ZuhdQKpVG0nTPYHNT57B4CNYgGD03A2oC1Dbnz5IWSOiE3gvkaKCmQouNqv6CPnuuxI7hM0IzXQqOJziVWfuIs7Dn1PUudaDUylECriU0YGZae/aYlWiBeOzQLaenQKeCaADHWAJ8zZvKgOPIgQETvFVvFwKymzAwuGmUCN0jNAt5RJmU3Ona+cBXKXHoYogVVI4RMFxIn3cB5u+e86TkLe6I5ignJDl5ZL9P5EsEEbC70HluNPNhD5H75bYakghszYS9IVrAaa8NWMQfFuw+OZQqxNYYW3pxkdB05Oem5WO1ZhYnORcbs5/c1iloFRWQG6ANU4HNnGTNDrMBcORITOqU6aFA0GlKUEgTfQ3FzPLk/jgNzQloKkqE0SmkdMTtyUYrVyRYTclGsSK1VMmgyJNWFkFxqmV/K777JR9iDALFiiBiWC0KCcUKKoaqoT2jMmFfCewUnFKfzit4ZRAVTOVas44miJ7VgKwsl51swVOwIikXFTYIbma9SFyLlWuab3fKdzwXIjEoNXgApVc8dFcsONcNUUa+YE9TpEQBTqSD5Wk/kRkidklbCtIG0KbiTidNVz0W3p/ORRhO5KGP0MCluENxg+MFwY0aHdOQ6PAKMxwECWM5IKUdQSOm2hBcBp3V/q2K+kjkLjtJ6bBlAIbfCtBHGcxgvM/7ZwI8urnm5vuLLxRVj8YzFE4syjAG/dfit0NwUmuuM247IfsCmqXIbK7dM+LMBYgUrWreNguSMlVLLjVwqI3WuBlbvK713SmkDZRmIa8904hhPlfG8lvTxMrG83PPy7D0/P3nDRdhx4Xf8Zjpll1r2Y0McPE0vhB2EveH7jAwRpjhzmfyo7fJwQA6gZBCT+hAq1WX1QPcV876CFDzmHGUZmE4D/aVnuBCG58b0LLF8vuNn51f82ekrft695ifNawpKNuVtWhFN2Q8NbAPhBppro7lO+PezdwzVQ8j50Yz3gR5ix1RnpdYSFK3eUkqtGEUR72/J3knH8Lyhv1D6L4TxsmAvRl5c3PDnF6/4xfIb/mLxFc/dNWc6clMarkuHk8JUPCUrEgVNoNHQVJCcZ90kPzqYPg6QAyjMqlbR3wVFBWYtJJ11DJcN2z9yDM9heDlx8mzHX734il9uvuJvFr/mJ/6al36BIkDLV3kPNYszZUdONbvoBC6CTAWJGTsISEcl7XGgfDKR+bA6MhM/vMe6hrJsmDaB8USPgXPzbMdPzt/xl+vf8Iv2FT/2N2xUUIREpreJXVEGCwA0LuNDJneF3EHqhNI5rPFICDWIu4NK90C9drbHCUSHrWPllvAdYkgIlLYhrwLTiTKe1W3iLkf+9OINvzz9mr9e/gd/7K956QKteJwoY0nsLbO3wGABxfBSaNpEXBRy50gLSJ3DtR6d+RTjOD/DDyUQ/T47rJRXiqv1xoGKlCzcxI6vhzP+1b/kt37Lf7prnBQcxmAbBgtc5SW70rLNLUEz625kWnumU48UoX3v0Nyi+wVqVjMNzME+/zAC0dGO3nFHMHa1KDuQMAQwsKxsp4ZXw4Z/0x+xcBNrNx6HiuaOhA6gzw1eCqftQN4ob05bxBzjqaDJEa6bGlz7odZBoj+AHnIE4na/Hhkw1NVJGRkzbsg0u0IJSuqUODX8drrgVXfKvy+eo1pw7raQclJpwaKJNC4fyZ2IsWom3m0i0aiekpTmuqmkct/OnKoWZ5+V/n8HjLstB/kuKBITbsz4XaGZy3Q3CnEMlOBJvq38RuzIdcwb5o2rZcZ3kbNNz3nX47SwbkYWy5F9gbh26CSkpeL6gDYBSS3WD7V98cBY8mAJ8S4Qx6aT6m3TKWdkiuhOabziRo8fHalV0qJupeI50nhTmUt5yA3EE0daed4WJRfhbDGwChONT8S2Bla3gLhQ3NLh2waJqYpWOWNZH7RtPh6QGYz6egbDzbzeuQpMmZlwrKTPi+B6h+sD5pXSaPUMldlDZNZLhDQrbsMkTJNjbAP70LJqIgToQiJlx9TWjJNbIXeKBVf50kFKJM4Z8OO2zcMVM5nV9rlMPwBy257Q21iyH8Apvp9qsFWtFdAcgE0EC4p5JW4CbuXIbdVSpkmJ0TFlRyr1fZwWcHV7FV+BtKAQPKgDrd77kLj6YJFZ3Fyaq1QCNwMid9uSUEvraSZ+h8bWndfozIaDrxM6PNhaSUuQKFiWo1hUHcowtaOIbU4wP2/XR0qJHweIfNczaNvqCSFUqq9aY8GdPq0Uu9UpbL7KnUa1cyClTmKWC0yF3NR4Yo3hfcG7jIphMGcQOMz6uO1EkA889vcHCBzL4+ohtyU6IscVtoMnlDKraoCUqmrNQBy6+jJLBYe9bjKvuKtB17yhrqBiR+XM5hpF/pAbfO9pV/S2qT0zWQuesuqwoJTGgZszhoFY1Tx1ypAqGZOcKzCz95hT8I6yasmLwPC8YThT+ufC+KwQTkfON3s2zXhUzmJ26KRolDp+stux5xMCD2W+Hx9DVI6R3ILHmkBZeCwoqXNVJnQHD6mtCTdpffAxIdkhY0ZmL6nZQcmrQFx5prUynQhxbZR14mQ5ctoOdC6hYlVszopkkESVA/Jha5bbbflAe1hQVUG8r4C0jrT0lFaZ1o4SILW1pqhSALNCDm40NBsa5+1SqoSYQ5UR43pWz84y/lnPj8+2vFjecN707HLDkAK7oWHYNrRbnZWzgt9mdD8h40SZ4sxlHiYjfhQgtw2qOV26GghLo+S54CoB4nKOAWEuQufVdBNoEiTdjlmaCkpcQ9wY8TwTzgZ+dH7Dy/UVmzCwdiN9DiRT4uRhdLgRdGQWmgvEVAleKY8Smj8KECuGOI5ddsl2DGzFUWn5QphOIbdGXhdMDZzN0ZIaW7LM3TeDpqBtpltOXC4HXiy3vFhccxZ6Tl3P+7xgl1pe9Rteb1ekbzuad0r3xuiujPbthLsZkO0e6/tZMPrcbPduCj288ewxJUDujLwosIm4UGia6hKqNv+JoGo4LSyayKqZuOx2PGt3PG9ueOa3BKkxY5tbxuK5GVv2+xa3VcJOCLtC2GV0H5F+wmKsnf9HbJeHAZKrbIdTZJhQEfy+wbQSt9zMWqs32kVksxz5cvOedRh50V7TamLtRjqNtBrpJLLSkTB3/aN5ojn+a3rGN9OGf7n6klc3a26+3tC8dSy/Frp3hdVvJ/z1iHt3g/VDvY7x43MFVSuAuz0QN6dQnTIaFY0OTXMgnb2g8Ynzds+zZstPuzdstOcLf0MnkaWOOIwghWhKRnidN+zSmrdpxVfDWQXj3ZLmnaO5ErqrQvs+428mdDvCMMI41kV6hGc8EBCrKzDFugp7j+SCd4pOGXOC7x2gTFvHkFd8vWmZkudyuaPfNFw2W/alredBdDx6xKt4yjfThl/vLnm13/Dq21Py+0D3jefkChavKxDttyPuZkTfb7G+p/RDjRsx/YCH7maZTuKEATIEVISwq6JwWtQzC3mhRAu8a5dMydG4zHVqiZ0jaKaVxGieoQS+6s943a/5zc2G7fUCfd3QvVcWr432vdG9zYTrCX+1r72Y/b5ukbtp9hMczfx4QA5eUgyTsaa7kpF9oOlHQtfQvFuQF1X/TAthPFmQuyW/Wp1jAf6xq5yEO3WK62sD2+/g2c5otoWwnQjXEbefkN2A9CM2DLXWOBzHzLd04FPY4zp3KdUHGahpGJCY8LngWo8bWkrraG58rTUWejyGafPBlyMgo+FHw+8Lvs+4fapA7EdkmLBhxGLt31pMn9Qr7trDO3dwe6o4JmQU6IdK/0NAnOJ9ZcXtgQ07Nytjd86o2eH00W2QPmayuQlld08wHw7o3nmOT2mP78sA2HymK2dMFEkJuyMtmt6eAoAPnD4CykEWmO/18Mud8+13M8j3+CGAT9eXuQvO4dnvCzUH6fF/HeMDafMzf9D6+/00xP3JPPLY9eewpw8Q3bMnQO6ZPP0zhO/ak4fcsydA7tkTIPfsCZB79gTIPXsC5J79D2NQSt6UYd6eAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXmRIBwfvmfb"
      },
      "source": [
        "Now we have two stuffs, one the ideal image and the actual image. We have to calculate the distance between them. \n",
        "\n",
        "- Mean absolute difference --> replaces negative with positive values\n",
        "- Mean Squared Error --> makes everything positive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAYiuCywT7L",
        "outputId": "4fdd2182-3e5a-4d30-d357-ca6bcf10b45f"
      },
      "source": [
        "# Creating a vlid 3 and 7 tensors\n",
        "\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path / 'valid' / '3').ls()])\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path / 'valid' / '7').ls()])\n",
        "\n",
        "# Converting them into 0 and 1 \n",
        "valid_3_tens = valid_3_tens.float() / 255\n",
        "valid_7_tens = valid_7_tens.float() / 255 \n",
        "\n",
        "# Shape of the valid tensors \n",
        "valid_3_tens.shape , valid_7_tens.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9VYtdVrxhC0",
        "outputId": "3ef3604c-bf7e-4b35-f1b0-c8b8ba63e04f"
      },
      "source": [
        "# Writing the function which cal dist btw ideal and arbitrary value\n",
        "# taking the mean ranging over the values indexed by the last two axes of the tensors\n",
        "def mnist_distance(a , b):\n",
        "  return (a - b).abs().mean((-1 , -2))\n",
        "\n",
        "# Using the function \n",
        "valid_3_dist = mnist_distance(valid_3_tens , mean_3)\n",
        "valid_3_dist.shape \n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1010])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYOIHoMIy2Pi",
        "outputId": "ebaf7cc3-118b-40d3-a069-d9466190b0b0"
      },
      "source": [
        "# The first 5 sample's distance \n",
        "valid_3_dist[:5]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1163, 0.1270, 0.1241, 0.1097, 0.1165])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmJUQYF8y7Tz",
        "outputId": "85d55f56-17b1-4c25-cd06-450bcd2ec813"
      },
      "source": [
        "# Taking one sample from 3 and 7 \n",
        "a_3 = stacked_threes[5]\n",
        "a_7 = stacked_sevens[6]\n",
        "\n",
        "len(a_3) , len(a_7)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC1h4dwzzUdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39811b0d-9ef1-42d0-8098-9abdcd24bf0a"
      },
      "source": [
        "# Calculating the distance between ideal and single image file \n",
        "mnist_distance(a_3 , mean_3) , mnist_distance(a_7 , mean_7)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1700), tensor(0.1542))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ghwS9bT044X",
        "outputId": "a2642f1b-051b-476b-bb80-3b937204b71c"
      },
      "source": [
        "# Function to check whether a tensor is 3 or not \n",
        "def is_3(x):\n",
        "  '''\n",
        "  the distance should between the tensor and the mean 3 should be less than the mean 7, we can call it as a 3\n",
        "  '''\n",
        "  return mnist_distance(x , mean_3) < mnist_distance(x , mean_7)\n",
        "\n",
        "# Passing one tensor \n",
        "is_3(a_3) # this is 3 and should return 3 "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5RffPDF3xSM",
        "outputId": "b59a7022-3e68-498a-d6ec-978e5ca6e1a7"
      },
      "source": [
        "# Passing our whole valid 3 set and see how it goes \n",
        "is_3(valid_3_tens)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True,  ..., True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbserpWV4MlV",
        "outputId": "0352551e-f928-4bf7-8bf6-7df2c946491b"
      },
      "source": [
        "# Alright now calculate the distance for 3 and 7 \n",
        "accuracy_3s = is_3(valid_3_tens).float().mean()\n",
        "\n",
        "# For 7 we will take the inverse of all the 7s (since we don't have is_7 function)\n",
        "accuracy_7s = (1 - (is_3(valid_7_tens).float().mean()))\n",
        "\n",
        "accuracy_3s , accuracy_7s"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9168), tensor(0.9854))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__n3fR949zF",
        "outputId": "12aaca4b-3995-45c4-f105-71eed985a74d"
      },
      "source": [
        "# It will perform worse since it's 7 \n",
        "is_3(valid_7_tens).float().mean()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0146)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WpDeltn5GiM"
      },
      "source": [
        "## SGD \n",
        "\n",
        "- This is something that will allow our model to get better and better which gives the **ability of learning to the model**.\n",
        "\n",
        "**How do we make it work?**\n",
        "- Assign a weight \n",
        "- Tweak the weight (parameters) and improve based on the weight assignment.\n",
        "\n",
        "**What can we do to our pixel similarity in order to apply SGD (or a optimizer)?**\n",
        "- Assign a weight for each pixel values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azmZCGxP6Rv-"
      },
      "source": [
        "# Probability of a number being 8\n",
        "def pr_eight(x , w):\n",
        "  '''\n",
        "  w = weights for the pixels \n",
        "  x = input image \n",
        "  '''\n",
        "  return (x*w).sum()"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecuPnNH6fIz"
      },
      "source": [
        "The above function will help us to update the weight `w` for every iteration and make our weight assignemnt better and better. \n",
        "\n",
        "> Converting the above function `pr_8` to a machine learning classifier: \n",
        "- Initialize the weights \n",
        "- For each image, use the weights that was initialized and predict whether it appears to be a 3 or a 7. (Step 2)\n",
        "- Based on the predictions, **calculate how good the model is** (*Calculte loss*). \n",
        "- Tweak (step) the weights based on the above calculation. \n",
        "- Go back again to Step 2, where you use the weights and make predictions. \n",
        "- Iterate this process until we decide to stop the training. \n",
        "\n",
        "#### Guidelines\n",
        "\n",
        "- **Initialize**\n",
        "\n",
        "    We initialize the parameters (or) weights to random values at first. It's believed starting with random weights (or) values works perfectly well. \n",
        "\n",
        "- **Loss**\n",
        "\n",
        "    A function will return a number that is small when the performance of the model is good. The standard approach is to treat a **small loss as a good and large loss as bad.** \n",
        "\n",
        "- **Step**\n",
        "\n",
        "    A simple way to figure out whether a weight should be increased a bit or decreased, would be just try to increase the **weight** by a small amount and observe the loss goes up or down. We do this **increment and decrement until we find an amount that satisfy us**. \n",
        "\n",
        "    However, we use calculus to take care of this. Finding which direction and roughly how much, to change each weight without doing those adjustments above. \n",
        "\n",
        "    We do this by calculating ***gradients.*** This is just an **performance optimization.**\n",
        "\n",
        "- **Stop**\n",
        "\n",
        "    This is the phase where we choose the epochs to train the model for, we would keep training until the accuracy of the model started getting worse or ran out of time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY227g6t7jBg"
      },
      "source": [
        "#### Calculating Gradients \n",
        "\n",
        "In here we will use calculus as a performance optimizartion. \n",
        "\n",
        "**But why ?**\n",
        "- It will help us quickly to calculate whether our loss will go up and down as we are adjusting the parameters.\n",
        "\n",
        "> Gradients will tell us how much we have to change each weight to make our model better\n",
        "\n",
        "**What the hell is a derivative?**\n",
        "- it calculates the change of a equation rather a value.\n",
        "- For instance, the derivative of the quadratic function at the value 3 tells us how rapidly the function changes at the value 3. \n",
        "\n",
        "**Exact definition of a gradient**\n",
        "\n",
        "*Gradient is defined as rise/run that is the change in the value of the function, divided by the change in the value of the parameter.*\n",
        "\n",
        "The takeaway: \n",
        "- When we know how our function would change, then we know what we need to do in order to make it smaller (loss function). \n",
        "- The key is having a function and change the parameter of the function to make the loss smaller. \n",
        "\n",
        "#### Things to know\n",
        "\n",
        "- The function will return not one but alot of weights, so when we calculate the derivative we will get alots of number, `i.e gradient for every weight`. \n",
        "- `requires_grad_()` special method tells pytorch we want to calculate gradients w.r.t to the variable at the value. For instance, in 3x (x). By doing this Pytorch, will keep track of all the computed gradients. \n",
        "- `backward` --> backpropagation, this is process of calculating the derivative (gradients) for each layer. \n",
        "- In `backward pass` we calculate the gradients of a neural network, and on `forward pass` we calculate the activations of a neural net.\n",
        "\n",
        "> **Backpropagation** is a training algorithm consisting of 2 steps: \n",
        "1. Feed forward the values \n",
        "2. Calculate the error and propagate it back to the earlier layers. So to be precise, forward-propagation is part of the backpropagation algorithm but comes before back-propagating.\n",
        "\n",
        "\n",
        "- https://datascience.stackexchange.com/questions/66416/forward-pass-vs-backward-pass-vs-backpropagation\n",
        "- https://stackoverflow.com/questions/28403782/what-is-the-difference-between-back-propagation-and-feed-forward-neural-network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UWWcBEu9_Yl",
        "outputId": "f3f498ea-61aa-4266-ea74-f7c0d0424593"
      },
      "source": [
        "# Calculating Gradients with Pytorch\n",
        "\n",
        "import torch \n",
        "\n",
        "# Creating a tensor (will keep track of the gradients of the value\n",
        "xt = tensor(8.).requires_grad_()\n",
        "\n",
        "# Sample function \n",
        "def f(x): return x**2\n",
        "\n",
        "# Performing some computations with xt\n",
        "yt = f(xt)\n",
        "yt"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(64., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w1-PKKNCjLS"
      },
      "source": [
        "# Telling pytoch to calculate the gradients by calling grad \n",
        "yt.backward() # always pass a function"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jnk7_VvFmLn",
        "outputId": "450f19e7-4506-4ad6-cbcf-cac2e85ec087"
      },
      "source": [
        "# Now viewing the gradients calculated on our variable \n",
        "xt.grad # now get the gradient on a variable"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB2KexQ8Fxk0"
      },
      "source": [
        "The graidents will tell us only the slope of our function, they don't really say how far we should adjust the parameters. \n",
        "\n",
        "https://en.wikipedia.org/wiki/Slope#Calculus\n",
        "\n",
        "- If slope is very large --> More adjustments to do \n",
        "- If slope is very small --> We are close to the optimal value. \n",
        "\n",
        "### Stepping (way to increase/decrease weight) with a Learning Rate \n",
        "- This is the idea of **multiplying the gradient by a small number** (that is the learning rate).\n",
        "- We can adjust the learning rate by, `w- = w.grad * lr`. \n",
        "\n",
        "This means we get the gradients and multiply the gradients with a learning rate. \n",
        "\n",
        "- If the learning rate is too low, optimization will take a lot of time because steps towards the minimum of the loss function are tiny.\n",
        "- If the learning rate is too high, it can result in getting the *loss* worse. Rather than diverging (or) converging it will bounce around. \n",
        "https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny3uebqcGfIa"
      },
      "source": [
        "### An End-to-End SGD Example \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfSrslPMiMI",
        "outputId": "87e8009c-fa7e-4819-f4c7-69df28a821ea"
      },
      "source": [
        "# Time \n",
        "time = torch.arange(0 , 20).float()\n",
        "# Time in seconds \n",
        "time"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "d0t5Egj3Mnqc",
        "outputId": "218360db-1190-4f08-c027-239ef6e48925"
      },
      "source": [
        "# Calculating the speed -> a*(t**2) + (b*t) + c\n",
        "speed = torch.randn(20)*3 + 0.75*(time -9.5)**2 + 1\n",
        "\n",
        "# Plotting the time and speed\n",
        "plt.scatter(time , speed)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fdee1d14c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFnGkvwxM-yO"
      },
      "source": [
        "def f(t , params):\n",
        "  a , b , c = params\n",
        "  return a*(t**2) + (b*t) + c"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pH2O7tCOL52"
      },
      "source": [
        "Every quadratic function returns 3 values a, b and c. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS-6susNOiLK"
      },
      "source": [
        "# Since we're on a continous data our loss function would be mse\n",
        "def mse(preds , targs):\n",
        "  return ((preds - targs)**2).mean()"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scsKo6IaO4Ow",
        "outputId": "c52d8fb1-8ff8-4d2b-dc93-b5753f346b44"
      },
      "source": [
        "# Firstly --> Initialize the parameters\n",
        "params = torch.randn(3).requires_grad_()\n",
        "params # a b c"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4424, 1.1436, 1.3470], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgJvercAPPFZ",
        "outputId": "a887476f-ea97-4fce-f4dd-176e0a58bd2f"
      },
      "source": [
        "# Calculating the predictions \n",
        "preds = f(time , params)\n",
        "preds"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.3470,   3.9330,   9.4039,  17.7596,  29.0001,  43.1255,  60.1357,  80.0307, 102.8106, 128.4753, 157.0249, 188.4592, 222.7785, 259.9825, 300.0714, 343.0451, 388.9037, 437.6471, 489.2753,\n",
              "        543.7884], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "nii6rWSaTbsJ",
        "outputId": "85b8db7f-b43b-4891-bc4c-a5053b1270fe"
      },
      "source": [
        "# A function to plot both targets and preds to see how close our predictins are\n",
        "\n",
        "def show_preds(preds , ax=None):\n",
        "  if ax is None: ax=plt.subplots()[1]\n",
        "  ax.scatter(time , speed)\n",
        "  ax.scatter(time , to_np(preds) , color='red')\n",
        "  ax.set_ylim(-300 , 100)\n",
        "\n",
        "show_preds(preds)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUmm-D7_TfWq",
        "outputId": "b5c4d971-2d5d-4157-95b0-39864b43a551"
      },
      "source": [
        "# Now the next step --> Calculate the loss\n",
        "loss = mse(preds , speed)\n",
        "loss"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(54397.4453, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYkSZQmrTz3B",
        "outputId": "2fd9ec88-3a5d-4680-b008-abbd1958fd0a"
      },
      "source": [
        "# Calculating the gradients (from the loss function)\n",
        "loss.backward()\n",
        "params.grad # for a,b,c we get the gradients"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([77785.1719,  5013.8418,   328.1294])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A8NsKmRUbcr",
        "outputId": "ed0832ac-5997-45e8-cf96-efe4a90be130"
      },
      "source": [
        "# Just multiplying lr with gradients \n",
        "params.grad * 1e-5"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7779, 0.0501, 0.0033])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5e624jJT-ot"
      },
      "source": [
        "# Stepping --> update the gradients with a learnin rate \n",
        "lr = 1e-5 # learning rate \n",
        "\n",
        "# Functionality that's help us in updating the learning rate \n",
        "params.data -= lr * params.grad.data\n",
        "params.grad = None\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4eKsGJXVVpR"
      },
      "source": [
        "# Putting everything into a function \n",
        "def apply_step(params , prn = True):\n",
        "  # Getting the predictions \n",
        "  preds = f(time , params)\n",
        "  # Calculate the loss \n",
        "  loss = mse(preds , speed)\n",
        "  # Initiating back prop on loss function \n",
        "  loss.backward()\n",
        "  # Stepping with a learning rate (multiplying the gradients with a lr)\n",
        "  params.data -= lr * params.grad.data\n",
        "  params.grad = None\n",
        "  if prn:\n",
        "    # Getting only the numbers (we don't want the tensors)\n",
        "    print(loss.item())\n",
        "  return preds\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU2rhhj2XtSb",
        "outputId": "dcea0618-f0cd-431c-b373-0b2883a94b5f"
      },
      "source": [
        "# Iterating \n",
        "for i in range(10):\n",
        "  apply_step(params)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10803.5302734375\n",
            "2554.22216796875\n",
            "993.1968994140625\n",
            "697.7977905273438\n",
            "641.8939208984375\n",
            "631.3098754882812\n",
            "629.3016357421875\n",
            "628.916259765625\n",
            "628.8380126953125\n",
            "628.81787109375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKJI0rQfX1Di"
      },
      "source": [
        "#### Summarizing Gradient Descent\n",
        "\n",
        "- At beginning, the weights of our model can be random (or) from pre-trained model.\n",
        "- We compare the model with our targets and prediction using a **loss function,** which returns a number that we want to make as low as possible by **improving our weights.**\n",
        "- To find how to change the **weights** to make the loss a bit better, we use calculus to **calculate the gradients.**\n",
        "- Calculating gradients is similar finding a steepest downward slope, we use the **magnitude of the gradient** (steepness of a slope) to tell us how big a step to take.\n",
        "- To decide on the step size, we multiply the gradient by a number we choose called the **learning rate.**\n",
        "- We then iterate until we have reached the lower point, and then stop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5eKqeHqYM0h",
        "outputId": "d37aa32f-a328-4d0e-ce33-d8a288dd95ce"
      },
      "source": [
        "# Changing them from a list of matrices (rank 3) to a list of vectors (rank 2)\n",
        "\n",
        "train_x = torch.cat([stacked_threes , stacked_sevens]).view(-1 , 28*28)\n",
        "train_x.shape"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12396, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfU3C9X1ZQjB"
      },
      "source": [
        ">`-1` > denotes the row, since we don't know how many rows exactly in a dataset (or) this image, we use -1. Which says make this axis as big as necessary to fit all the data. Like we do in slicing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFYUecR4ZW6G",
        "outputId": "9f6e8698-4772-469b-aa3a-50615b6e4499"
      },
      "source": [
        "# Constructing our labels (3s -> 1 & 7s -> 0s)\n",
        "\n",
        "train_y = tensor([1] * len(threes) + [0] * len(sevens)).unsqueeze(1)\n",
        "train_y.shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12396, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HttCCq-PZhYt",
        "outputId": "20956e09-ab43-44b5-ff53-32e52ee28a52"
      },
      "source": [
        "# Zipping x and y into a dataset \n",
        "dset = list(zip(train_x , train_y))\n",
        "x , y = dset[0] # take one sample\n",
        "\n",
        "# Checking the shape \n",
        "x.shape , y.shape"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ0urfk9Zv4l",
        "outputId": "8325bcef-1d41-407a-ff81-8c853854ee52"
      },
      "source": [
        "# x and y \n",
        "\n",
        "print(f'Images in Tensor (sliced) : {x[0 : 100]}')\n",
        "print('----------------- ------------ --------- -------')\n",
        "print(f'Labels: {y}')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images in Tensor (sliced) : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "----------------- ------------ --------- -------\n",
            "Labels: tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYPS8e_OZ2z1"
      },
      "source": [
        "# Doing the exact thing for our validation set \n",
        "\n",
        "valid_x = torch.cat([valid_3_tens , valid_7_tens]).view(-1 , 28*28)\n",
        "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
        "\n",
        "# Putting them into a dataset \n",
        "valid_dset = list(zip(valid_x , valid_y))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh_ztb-haIHa"
      },
      "source": [
        "**Initialize the parameters with random numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMWsqr5FaMHT"
      },
      "source": [
        "# Generate weight for every pixel \n",
        "def init_params(size , std = 1.0):\n",
        "  return (torch.randn(size) * std).requires_grad_()\n",
        "\n"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr7y2mXtatRr",
        "outputId": "368ec251-bd0e-4afd-c425-291e010fbf62"
      },
      "source": [
        "# Using the function and creating random weights \n",
        "weights = init_params(size = (28*28 , 1) , std=1.0)\n",
        "weights.shape"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqNV1yb3a_DY"
      },
      "source": [
        "# Initializing bias \n",
        "\n",
        "bias = init_params(1)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGjAbkVFbDBc",
        "outputId": "4d94122d-f66c-469e-9f9f-ad492907b66e"
      },
      "source": [
        "# Prediction on one image \n",
        "(train_x[0] * weights.T).sum() + bias\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8.1409], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRRVFphabkpU"
      },
      "source": [
        "Alright so far we have made a initializer function that gives us random weights, we got: \n",
        "- Function to calculate the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2LU4YMkBjr-",
        "outputId": "d3272b82-378b-4383-8c12-3b71fccc36c0"
      },
      "source": [
        "# Constructing the matrix multiplication function (y = wx + b)\n",
        "\n",
        "# As we can say our tiny model indeed \n",
        "def linear1(xb):\n",
        "  '''\n",
        "  xb --> Input training batch\n",
        "\n",
        "  We return by multiplying the weights to our each input mini-batch\n",
        "  '''\n",
        "  return xb@weights + bias\n",
        "\n",
        "# Getting the predictions for all images in the training set (x)\n",
        "preds = linear1(train_x)\n",
        "preds[:10]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.1409],\n",
              "        [-2.2279],\n",
              "        [13.6280],\n",
              "        [ 2.5632],\n",
              "        [-7.1215],\n",
              "        [-2.3965],\n",
              "        [ 6.0359],\n",
              "        [ 5.5989],\n",
              "        [-4.2894],\n",
              "        [ 2.9472]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mWmLm7rCYOm"
      },
      "source": [
        "Looking back before jumping into calculus and other stuffs first we make a prediction on our input data, then observe how the model/function performs? Not well? \n",
        "\n",
        "Alright we will decide that by passing the preds and targs into a loss function. And we know our goal is to minimize the loss so now we we will get the help of calculus (gradients) that will help our loss function to find the minimum. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVjfs3TcDEUg"
      },
      "source": [
        "# Calculating the accuracy\n",
        "corrects = (preds > 0.0).float() == train_y"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjC4c1YBDR2O"
      },
      "source": [
        "# Manually tweaking one value of the weight matrix \n",
        "with torch.no_grad():\n",
        "  weights[0] *= 1.001\n"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So3Pu87LK_sp"
      },
      "source": [
        "Making a change with just `weights[0] *=1.001` throws an error, this is because we are trying to access even the graidents and make a change in that. \n",
        "\n",
        "By using with `torch.no_grad()` we can turn of the gradients and make computations just on the value of the matrices. \n",
        "\n",
        "https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch\n",
        "\n",
        "Gradients tells the loss function how to make changes in order to tweak the weights. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6y7oqR6DSiD"
      },
      "source": [
        " \n",
        "\n",
        "Reads: \n",
        "- https://discuss.pytorch.org/t/what-is-the-purpose-of-is-leaf/87000/5\n",
        "- https://stackoverflow.com/questions/57188409/assigning-a-parameter-to-the-gpu-sets-is-leaf-as-false\n",
        "- https://forums.fast.ai/t/weights-0-in-place-operations/89308\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-QbwOf0EZo0",
        "outputId": "6ddb6711-d9e6-4f13-f982-420ab342f5ff"
      },
      "source": [
        "# Making the prediction after manually tweaking the value \n",
        "preds = linear1(train_x)\n",
        "\n",
        "((preds > 0.0).float() == train_y).float().mean().item()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5375927686691284"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02x4ogu2MYAJ"
      },
      "source": [
        "If we are going to use accuracy as an performance metric the slight changes in the weight won't make a difference in the loss function. \n",
        "\n",
        "So we need a metrics where little changes on the weight matrice should make a impact on the loss function. \n",
        "\n",
        "> We need a loss function that when our weights result in slightly better predictions, gives us a slightly better loss.\n",
        "\n",
        "The only thing our model will do is, given a number predicts it whether an 3 or not. if it's not 3 then it has to be 7. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vq14I66IdpU"
      },
      "source": [
        "# Calculating the loss \n",
        "trgts = tensor([1 , 0 , 1])\n",
        "prds = tensor([0.9 , 0.4 , 0.2])\n",
        "\n",
        "# Creating our own loss function \n",
        "def mnist_loss(predictions , targets):\n",
        "  return torch.where(targets == 1 , 1 - predictions , predictions).mean()"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRvyTYJ2M_2a",
        "outputId": "31b52d79-428a-4d0b-ec71-901d9c1d9dff"
      },
      "source": [
        "mnist_loss(prds , trgts)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4333)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTGqhz2PO9Ni"
      },
      "source": [
        "# Importing utils from the fastbook \n",
        "\n",
        "#!pip install -q fastbook \n",
        "#from fastbook import *"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "-9BKCgYZNeLe",
        "outputId": "708649bf-2df1-4197-debc-5abef54e956b"
      },
      "source": [
        "# Example of sigmoid from Pytorch function\n",
        "\n",
        "plot_function(torch.sigmoid , title='Sigmoid' , min=-4 , max=4)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEMCAYAAAA/Jfb8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3G8c8XCCQkJGwh7DvIpoBEEBStVety61ZstSrutaLWrfXW6tVatbW112urtS63KIriWnGjaqtWxaXKGiDs+04Cgex7vvePCb0xJmaAJGdm8rxfr3npnPnN8BhnHk5+58zvmLsjIiKxpVXQAUREpPGp3EVEYpDKXUQkBqncRURikMpdRCQGqdxFRGKQyl1ijpndZWZrg86xn5nNMLP3GhhzqZlVNFcmiX0qd4kqZpZgZveY2RozKzazHDObZ2bX1xj238DRQWWsww3A94MOIS1Lm6ADiBygR4ETCBVmBpAMjAX67h/g7gVAQSDp6uDuuUFnkJZHe+4Sbc4Gfu/ur7n7BnfPcPcZ7n73/gF1TcuY2Y1mttXMiszsXTObamZuZr2rH7/UzCrM7AQzW1r9W8GHZtbTzI4zs0VmVmhm75lZr1qvfYmZLTezsuo/414za1Pj8a9My5hZq+rfPrLMrMDMXgQ6NdUPTFomlbtEmx3AqWbWOdwnmNn3CE3V/B4YDTwP/K6Ooa2AXwJXAscAvYAXgbuBadXbegP/U+O1/wN4EpgJjAJ+Clxb/Tr1+QlwM3ALcCSwoIHxIgfO3XXTLWpuhAp2E1AJLAGeILQ3bzXG3AWsrXH/U2Bmrdf5LeBA7+r7l1bfH1NjzC3V28bV2HYTsLvG/bnAS7Ve+wagGGhbfX8G8F6Nx7cCv671nFeAiqB/vrrFzk177hJV3P1TYBAwGXgaSCNUjG+YmdXztBHAv2pt+7yulweW1ri/s/qfS2pt62JmravvjwQ+rvU6HwHx1Tm/wsySCf1G8Fmthz6pJ7vIQVG5S9Rx9wp3/8zdH3D3swjtdX8XOO6bnhbGS1e5e2Xt57h7eR2vU99fJCIRQeUusWBF9T+71fP4cmBirW2NdapkJl//S+V4QtMy62oPdvc8YBswqdZDxzRSHhFAp0JKlDGzjwgdEJ0PZAODgd8A+4B/1vO0B4AXzexL4G1CxXpx9WOHekGD+4A3zexW4FVgDKE5/wfcvewb8txjZisJTRedCZx0iDlEvkJ77hJt3gYuBP4GrAKeAtYAx7j77rqe4O6vAv8J3EpoTv1C4FfVD5ccShh3/xtwOXAJsAx4EPhzjdevyx+Bh6rHLib0W8Xd3zBe5ICZu67EJC2Pmd0JXO/uXYPOItIUNC0jMc/M4gidf/43oJDQN1xvAR4JMpdIU9Keu8S86m+LvgWMAzoAG4BnCH3TVYt1SUxSuYuIxCAdUBURiUERMefetWtX79+/f9AxRESiyoIFC3a7e2pdj0VEuffv35/58+cHHUNEJKqY2ab6HtO0jIhIDAqr3M3sOjObb2alZjajgbE3mdlOM8szsyfNrF2jJBURkbCFu+e+HbiX0LrV9TKzUwh9C/BEoB8wkG/+pp6IiDSBsMrd3V9199eAPQ0MvQSY7u6Z7r4XuIfQin0iItKMGnvOfSSh61rulwGkmVmXRv5zRETkGzR2uScBNS8GvP/fO9QeaGZXVc/jz8/Ozm7kGCIiLVtjl3sBoavR77f/3/NrD3T3J9w93d3TU1PrPE1TREQOUmOf555J6ALEL1XfHw3scveG5upFRGKau5NTWMbOvBKy8krJyi9hV14pY/t2ZPKQxt/BDavcqxdeagO0BlqbWTyhi/nWXnTpGWCGmT1H6Ayb/yJ0cWARkZhWVlHFtn3FbN1bxNa9xWzbW8z2fcVs21fMjtwSduaVUFZR9bXnTfvWoODKnVBJ/7LG/YuAX5nZk4QuYTbC3Te7+ztmdj+hK+IkAH+t9TwRkahVXlnF5pwi1mcXsmF3ARt2F7FxdyGbc4rYkVtMVY11GFu3Mronx9OzYzxj+nSkR8d4uieHbt2S4+nWoR2pHdoRH9e6/j/wEETEqpDp6emu5QdEJFJUVjkbdhewcmc+q3cVsGZXPmuyCti0p5Dyyv/vzE7t4+jfNZF+ndvTt0sifTu3p0+nBHp3bk9ah3a0ad20iwCY2QJ3T6/rsYhYW0ZEJCgl5ZWs2pnP0m25ZG7PJXN7Hqt25lNaPYXSyqBfl0QGd0vi5BFpDE5NYmBqIgO7JpHSPi7g9PVTuYtIi+HubM4pYsGmvSzavI+MrftYsSPv33vjKQlxjOyZzNSj+zG8RzLDenRgUGpSk02dNCWVu4jErKoqZ8XOPL5Yn8OXG3KYv2kvuwtKAUhs25ojenfkyskDOaJXCqN6pdC7UwJmFnDqxqFyF5GYsnF3IZ+s3c2na3fz2bo95BaXA9C7UwKTh3RlXL9OpPfvxJBuHWjdKjaKvC4qdxGJaiXllXy+bg8frsriw9XZbNpTBEDPlHi+MyKNiYO6MGFgF3p1TAg4afNSuYtI1NlXVMY/lu/ivRW7+Hj1borLK4mPa8WkQV254tgBTB6SSv8u7WNmiuVgqNxFJCrsLSzjncyd/G3pDj5ft4eKKqdHSjznjuvNicO7cfTALlF54LOpqNxFJGIVl1Xy9+U7eWPxdj5anU1FldOvS3t+dNxAThvVncN7pbTovfNvonIXkYji7izcvJdXFmzlrYwd5JdW0D05nsuPHcCZo3sysmeyCj0MKncRiQi5ReX8deFWZn25mbVZBSTEteb0w3swZVwvjh7QhVYxfGZLU1C5i0iglm/PY8ZnG3h98XZKK6oY3acj9085gtOP6EFSO1XUwdJPTkSaXVWV896KXUz/ZANfbMghPq4V3zuyNxcd3ZeRPVOCjhcTVO4i0mxKKyp5bdE2Hv94PeuzC+nVMYHbTh/Geel9I3qdlmikcheRJldSXskLX27msY/WszOvhJE9k3noh2M5fVT3Jl85saVSuYtIkykpr+S5Lzbz2EfryM4vZfyAzvz++0dw7OCuOuOliancRaTRVVRW8cqCrfzx/TXsyC1h0qAuPPzDsRw9sEvQ0VoMlbuINBp3570VWdz39grWZxcypk9HHvj+aCYN7hp0tBZH5S4ijWLZtlzueWs5X2zIYWBqIk9MHcfJI9I0/RIQlbuIHJKcwjJ+/+4qXpi3mU7t23LPWSM5f3xf4nSgNFAqdxE5KFVVzqwvN/P7d1dRUFrBZZMGcOPJQ0iO1ymNkUDlLiIHbOXOPH7x6lIWbd7HxIFd+NVZIxma1iHoWFKDyl1EwlZSXslD76/hiY/Xk5wQx4PnjebsMb00rx6BVO4iEpZFm/dyyytLWJtVwLnjenP76cPplNg26FhSD5W7iHyj0opKHvzHGp74eB1pyfE8ffl4jh+aGnQsaYDKXUTqtXpXPje8sJgVO/I4L70Pt393uA6YRgmVu4h8jbvz9Gcbue/tlSS1a8NfLk7npBFpQceSA6ByF5Gv2FdUxs9eXsJ7K3ZxwmGp3H/uaFI7tAs6lhwglbuI/NuCTXu5/vlFZOWXcMd3R3D5Mf11JkyUUrmLCO7OU59u5Dd/W0GPjvG8cvUkRvfpGHQsOQQqd5EWrqisgl+8upTXF2/npOFpPPCD0aQk6KBptFO5i7Rgm/cUcdXM+azalc8tpxzGtOMH6ULUMSKslX3MrLOZzTazQjPbZGYX1DOunZk9Zma7zCzHzN40s16NG1lEGsPn6/Zw1iOfsCO3hBmXjefaEwar2GNIuMu2PQKUAWnAhcCjZjayjnE3ABOBI4CewF7g4UbIKSKNaNYXm5k6/Qu6JLXj9WuP0ZeSYlCD5W5micAU4A53L3D3T4A3gKl1DB8AvOvuu9y9BHgRqOsvAREJQGWVc89by7lt9lKOHdKVV6+ZRP+uiUHHkiYQzpz7UKDC3VfX2JYBHF/H2OnAH82sJ7CP0F7+24ecUkQOWXFZJTe+uIh3M3dx6aT+3PHdEbTWNEzMCqfck4C8WttygbrW91wDbAG2AZXAUuC6ul7UzK4CrgLo27dvmHFF5GDsKSjliqfnk7F1H3d+dwSXHzsg6EjSxMKZcy8AkmttSwby6xj7CNAO6AIkAq9Sz567uz/h7ununp6aqvk+kaayJaeIcx/7nJU783jsonEq9hYinHJfDbQxsyE1to0GMusYOwaY4e457l5K6GDqeDPT1XFFArBiRx5THv2MnMIynrtyAqeM7B50JGkmDZa7uxcS2gO/28wSzewY4CxgZh3D5wEXm1mKmcUB1wDb3X13Y4YWkYbN25jDDx7/nFZmvHz1RMb16xx0JGlG4Z4KeQ2QAGQBzwPT3D3TzCabWUGNcT8DSgjNvWcDpwPnNGJeEQnD3DXZTJ3+BalJ7Xhl2kRdAq8FCusbqu6eA5xdx/a5hA647r+/h9AZMiISkL9n7uS6WYsYmJrIzCsmaEXHFkrLD4jEkDcztnPji4sZ1SuFpy87io7tdRm8lkrlLhIjXl+8jZteXEx6v85MvzSdDrpiUoumcheJAa8t2sbNLy3mqP6defLSo0hsp492S6d3gEiU21/s4weEir19W32sReUuEtXmLNnBzS8tZsKALjx56VEktG0ddCSJEOGeCikiEebvmTu54YVFHNm3E9MvTVexy1eo3EWi0Eers7lu1iJG9krhqcs0FSNfp3IXiTLzN+bw45nzGdQtiWcuG6+zYqROKneRKLJ8ex6XzZhHz5QEZl4xnpT2Knapm8pdJEps2F3IxU9+SVK7Nsy8cgJdk/TNU6mfyl0kCmTllTB1+hdUuTPzign06pgQdCSJcCp3kQiXV1LOJU/NI6ewjBmXHcXgbkkNP0laPJW7SAQrrajk6pkLWLMrn8cuGscRvTsGHUmihM6fEolQVVXOz15ewmfr9vDgeaM5bqiuWCbh0567SIT63bsreTNjO7eeNoxzxvYOOo5EGZW7SAR69l+bePyj9Vx0dF9+fNzAoONIFFK5i0SYD1bu4s7Xl/HtYd2464yRmFnQkSQKqdxFIsjy7XlcN2sRI3om8/APx9KmtT6icnD0zhGJEFl5JVz59DxSEuKYfonWZJdDo3ePSAQoLqvkR8/MZ19xOS9fPZG05PigI0mUU7mLBCx0ymMGS7bl8vhF4xjZMyXoSBIDNC0jErCHPljDnKU7uPXUYXxnZPeg40iMULmLBOjtpTv4w3trmHJkb67SKY/SiFTuIgHJ3J7LzS9lMLZvR359ziid8iiNSuUuEoDdBaVc9cwCOraP4/Gp44iP0yXypHHpgKpIMyuvrOLa5xayu6CUV66eRLcOOjNGGp/KXaSZ/XrOCr7YkMOD543m8N46M0aahqZlRJrRy/O3MOOzjVxx7AAtBiZNSuUu0kyWbN3H7a8tY9KgLvzitGFBx5EYp3IXaQZ7Ckq5euYCUpPa8acLjtSaMdLkNOcu0sQqKqu4/oVF7C4s469XT6JzYtugI0kLENbug5l1NrPZZlZoZpvM7IJvGHukmX1sZgVmtsvMbmi8uCLR57//vppP1+7h3rNH6QCqNJtw99wfAcqANGAMMMfMMtw9s+YgM+sKvAPcBLwCtAV01EharHeW7eSxj9ZxwYS+/CC9T9BxpAVpcM/dzBKBKcAd7l7g7p8AbwBT6xh+M/Cuuz/n7qXunu/uKxo3skh0WJ9dwM9ezmB0n4788owRQceRFiacaZmhQIW7r66xLQMYWcfYo4EcM/vMzLLM7E0z69sYQUWiSVFZBdOeXUhca+PPFx5Juzb6Bqo0r3DKPQnIq7UtF+hQx9jewCXADUBfYAPwfF0vamZXmdl8M5ufnZ0dfmKRCOfu3D57Gauz8vnD+WPp1TEh6EjSAoVT7gVAcq1tyUB+HWOLgdnuPs/dS4BfAZPM7GtHkdz9CXdPd/f01NTUA80tErGe+2Izsxdt48YTh3L8UL23JRjhlPtqoI2ZDamxbTSQWcfYJYDXuO91jBGJWUu35nL3m8s5bmgqP/n24KDjSAvWYLm7eyHwKnC3mSWa2THAWcDMOoY/BZxjZmPMLA64A/jE3XMbM7RIJMotKueaWQvoktSWP5w3hlattISvBCfcr8ldAyQAWYTm0Ke5e6aZTTazgv2D3P0D4DZgTvXYwUC958SLxAp352evZLBjXwl/uuBIfVFJAhfWee7ungOcXcf2uYQOuNbc9ijwaKOkE4kSf5m7gX8s38Ud3x3BuH6dgo4jorVlRA7Vgk17+d07Kzl1ZHcuP6Z/0HFEAJW7yCHZW1jGT2YtpEfHeH537hG6VJ5EDC0cJnKQqqqcn76cwe6CMv46bRIpCXFBRxL5N+25ixyk/527ng9WZnH7fwzXgmAScVTuIgdhwaYc7n93Facf3p2LJ/YLOo7I16jcRQ5QaJ59Eb06JvDbKZpnl8ikOXeRA+Du/KzGPHtyvObZJTJpz13kAPxl7gbeX5nFbacP0zy7RDSVu0iYFm0Onc9+ysg0LpnUP+g4It9I5S4Shtyicq6btYjuKfHcf+5ozbNLxNOcu0gD3J2f/3UJu/JKePnqiTqfXaKC9txFGvDM55t4J3MnPz91GGP7at0YiQ4qd5FvsGxbLr+es4JvD+vGlZMHBB1HJGwqd5F65JeUc92shXRJassD39c8u0QXzbmL1MHduW32MrbsLeaFq46mk9ZnlyijPXeROrw4bwtvZmzn5pOHclT/zkHHETlgKneRWlbtzOeXb2Ry7OCuTDt+UNBxRA6Kyl2khqKyCq6dtZAO8XE8qOugShTTnLtIDXe+nsm67AKevWICqR3aBR1H5KBpz12k2l8XbOWVBVv5ybeHcMzgrkHHETkkKncRYG1WPv/12jLGD+jMDScOCTqOyCFTuUuLV1xWybXPLSKhbWseOn8srTXPLjFAc+7S4t31RiarduXz9OXj6Z4SH3QckUahPXdp0V5btI0X52/hmm8N4vihqUHHEWk0KndpsdZmFXDb7KUc1b8TN588NOg4Io1K5S4tUmiefSHxca156IdjadNaHwWJLZpzlxZp/zz7jMuOokdKQtBxRBqddlekxXl14VZenL+Fa08YxLcO6xZ0HJEmoXKXFmXNrnxunx06n/2mkzTPLrFL5S4tRmFpBdOeW0hiu9b8SfPsEuM05y4tgrtz++ylrK9eN6Zbss5nl9gW1q6LmXU2s9lmVmhmm8zsggbGtzWzFWa2tXFiihyaWV9u5rXF27nppKFM0rox0gKEu+f+CFAGpAFjgDlmluHumfWMvwXIBjocekSRQ7Nk6z5+9cZyjh+ayrUnDA46jkizaHDP3cwSgSnAHe5e4O6fAG8AU+sZPwC4CLivMYOKHIx9RWVMe3YhqR3aaX12aVHCmZYZClS4++oa2zKAkfWMfxi4DSg+xGwih6SqyrnxxcVk55fy5wuPpLOugyotSDjlngTk1dqWSx1TLmZ2DtDa3Wc39KJmdpWZzTez+dnZ2WGFFTkQD3+wlg9XZXPnGSMY3adj0HFEmlU45V4AJNfalgzk19xQPX1zP3B9OH+wuz/h7ununp6aqgWbpHF9uCqLP7y/mnPG9uLCCX2DjiPS7MI5oLoaaGNmQ9x9TfW20UDtg6lDgP7AXDMDaAukmNlO4Gh339goiUUasHlPETe8sJjD0jrwm3MOp/r9KNKiNFju7l5oZq8Cd5vZlYTOljkLmFRr6DKgT437k4A/AUcSOnNGpMkVl1Vy9bMLcHcenzqOhLatg44kEohwv6J3DZAAZAHPA9PcPdPMJptZAYC7V7j7zv03IAeoqr5f2STpRWpwd25/bSkrdubxx/PH0q9LYtCRRAIT1nnu7p4DnF3H9rmEDrjW9ZwPgd6HEk7kQDzz+SZeXbiNG08awgnDtCCYtGxaXENiwufr9nD3W8s5aXga139bF7gWUblL1Nu2r5hrZy2kf5f2PHjeaH1RSQSVu0S5kvJKfjxzPuUVVTxxcTod4uOCjiQSEbQqpEQtd+eWV5aQuT2Pv1yczqDUOg//iLRI2nOXqPXnD9fxZsZ2bjnlME4cnhZ0HJGIonKXqPT3zJ38/t1VnDWmJ9OOHxR0HJGIo3KXqLNyZx43vbiY0b1T+N2UI/QNVJE6qNwlqmTnl3LFjPkkxbfh8anpxMfpG6giddEBVYkaJeWVXDVzPjmFZbx89US6p+hSeSL1UblLVNh/Zsyizft47KJxjOqVEnQkkYimaRmJCg/+YzVvZmzn56cO49RR3YOOIxLxVO4S8V6at4WHPljLeel9uPr4gUHHEYkKKneJaHPXZHPb7KUcNzSVe88ZpTNjRMKkcpeItWJHHtOeXcjgbkk8csFY4lrr7SoSLn1aJCJt3VvEpU99SVK7Njx12VFaM0bkAKncJeLsLSzj4ie/pLiskmeuGE+PlISgI4lEHZ0KKRGluKySy5+ex9a9xTx7xQSGpnUIOpJIVNKeu0SMsooqrnluARlb9vHQ+WMZP6Bz0JFEopb23CUiVFY5P305g3+uyua+7x2uc9lFDpH23CVw7s6dry/jzYzt3HraMH44vm/QkUSinspdAuXu3P/uKp77YjNXHz+Iq7V8r0ijULlLoB56fy2PfriOCyb05eenHhZ0HJGYoXKXwDz+0ToefG81547rzb1n6dunIo1J5S6BeOrTDdz39krOGN2T3005glatVOwijUlny0ize/KTDdz91nJOHdmd//nBaFqr2EUancpdmtVf5q7n3jkrOHVkdx7WejEiTUafLGk2+4v9tFEqdpGmpj13aXLuzsMfrOV//rGa/zi8B384f4yKXaSJqdylSbk7v31nJY9/tJ4pR/bmd1MOp42KXaTJqdylyVRWOb98YxnP/mszU4/ux6/OHKmzYkSaicpdmkRpRSU3v5jBnKU7+PHxA7n11GE6j12kGYX1+7GZdTaz2WZWaGabzOyCesbdYmbLzCzfzDaY2S2NG1eiQUFpBZfPmMecpTu4/fTh/OK04Sp2kWYW7p77I0AZkAaMAeaYWYa7Z9YaZ8DFwBJgEPB3M9vi7i80VmCJbFl5JVz+9DxW7Mjnge+PZsq43kFHEmmRGtxzN7NEYApwh7sXuPsnwBvA1Npj3f1+d1/o7hXuvgp4HTimsUNLZFq9K59z/vwZ67ML+cvF6Sp2kQCFMy0zFKhw99U1tmUAI7/pSRb6PXwyUHvvXmLQp2t3M+XPn1FWWcVLP57ICcO6BR1JpEULp9yTgLxa23KBhq5/dlf16z9V14NmdpWZzTez+dnZ2WHEkEj13BebuOTJL+nRMZ7Xrj2GUb1Sgo4k0uKFM+deACTX2pYM5Nf3BDO7jtDc+2R3L61rjLs/ATwBkJ6e7mGllYhSUVnFPW8t5+nPN3H80FQevmAsyfFxQccSEcIr99VAGzMb4u5rqreNpp7pFjO7HLgVOM7dtzZOTIk0OYVlXP/8Ij5Zu5sfTR7AracN1wJgIhGkwXJ390IzexW428yuJHS2zFnApNpjzexC4DfACe6+vrHDSmRYujWXq59dQHZBKfefewQ/SO8TdCQRqSXc74FfAyQAWcDzwDR3zzSzyWZWUGPcvUAXYJ6ZFVTfHmvcyBKkl+ZvYcpjnwHwytUTVewiESqs89zdPQc4u47tcwkdcN1/f0DjRZNIUlRWwZ2vZ/LKgq0cO7grD/1wLJ0T2wYdS0TqoeUHpEGrduZz7ayFrMsu4PoTh3DDiUM0vy4S4VTuUi9359kvNvPrOctJahfHs1dM4JjBXYOOJSJhULlLnbLzS/n5X5fwwcosjhuayn9//wi6dYgPOpaIhEnlLl/zzrKd3D57KfmlFdx1xggunthfS/WKRBmVu/xbTmEZv3wjkzcztjOyZzLPnzeGoWkNfRFZRCKRyl1wd+Ys3cFdb2SSW1zOzScPZdq3BulSeCJRTOXewm3JKeLO15fxz1XZHN4rhZlXTGB4j9qrTYhItFG5t1ClFZVM/2QDD7+/FjO447sjuGRiP13fVCRGqNxboA9XZfGrN5ezYXchJ49I464zR9KrY0LQsUSkEancW5A1u/K57+2VfLAyi4FdE3n68vEcPzQ16Fgi0gRU7i1Adn4pf3hvNS/M20L7tq35xWnDuOyYAbRtoykYkVilco9huUXlPDF3HU9+spHyyiqmHt2P608cojVhRFoAlXsMyisp5+lPN/K/c9eTV1LBmaN7ctPJQxnQNTHoaCLSTFTuMWRfURlPfbqRJz/dQH5JBScN78bNJx/GiJ46tVGkpVG5x4Bt+4qZPncDL8zbTFFZJaeMTOMn3x6ia5mKtGAq9yi2eMs+nvp0A28t2YEBZ4zuyVXHDdSXkERE5R5tSsoreWfZTmZ8tpHFW/aR1K4Nl0zszxWTB+hcdRH5N5V7lFifXcDzX27mlQVb2VtUzoCuidx1xgjOTe9DUjv9bxSRr1IrRLC8knLmLNnBKwu2smDTXtq0Mk4ekcaFE/oxaVAXLcMrIvVSuUeYkvJKPlyVzRsZ23h/RRalFVUM7pbEracN43tje9EtWRfMEJGGqdwjQEl5JR+vzubtZTt5b8Uu8ksq6JrUlvOP6sPZY3sxpk9HzLSXLiLhU7kHJKewjH+uzOK9Fbv4eHU2hWWVpCTEccrI7pw5uieTBnXRCo0ictBU7s2ksspZti2XD1dl89HqLBZv2UeVQ1pyO84c04vTRnVn4qAuukCGiDQKlXsTcXfWZRfyr/V7+HTtbj5bt4fc4nLM4IheKVz37SGcNLwbo3qm6MCoiDQ6lXsjKa+sYsWOPOZv3Mv8TTl8uSGH3QVlAPRMiec7I9I4dkhXjh3clS5J7QJOKyKxTuV+ENydrXuLWbotl8Vb9rF4yz6Wbs2luLwSCJX55CGpTBjQmQkDu9C/S3sdEBWRZqVyb0BZRRXrsgtYuTOPFTvyWb49j2Xbc9lXVA5A29atGNEzmfOO6kN6/04c2bcTPfVNUREJmMq9Wkl5JRt2F7Iuu4C1WQWsySpg9c58NuwupKLKAWjbphVD05I4bVR3RvVKYVTPFIb3SNZFL0Qk4rSocs8tLmfr3iK25BSxaU8Rm3OK2LinkI27i9ieW4yHOhwz6NOpPUPTkjhpRBrDundgeI9kBnZN1OmJIhIVYqbcC0sryAMVYosAAAVeSURBVMovZUduMbvyStiZW8r2fcXsyC1m274Stu4tIr+k4ivP6dg+jv5dEhk/oDP9uyQyMDWRwd2SGNA1kfi41gH9l4iIHLqoLvd/rszi7reWk5VXQmFZ5dceT0mIo2fHBHqmxDO+fyd6d2pPr04J9O3cnj6d25OSEBdAahGRphdWuZtZZ2A68B1gN/ALd59VxzgDfgtcWb3pL8Ct7vsnPBpXx/ZxjOiRzLcOS6Vbh3i6dWhHj5R4ulff2reN6r+7REQOWrjt9whQBqQBY4A5Zpbh7pm1xl0FnA2MBhz4B7ABeKxx4n7V2L6deOTCTk3x0iIiUa3Bo4NmlghMAe5w9wJ3/wR4A5hax/BLgAfcfau7bwMeAC5txLwiIhKGcE79GApUuPvqGtsygJF1jB1Z/VhD40REpAmFU+5JQF6tbblAh3rG5tYal2R1fD3TzK4ys/lmNj87OzvcvCIiEoZwyr0AqH3F5WQgP4yxyUBBXQdU3f0Jd0939/TU1NRw84qISBjCKffVQBszG1Jj22ig9sFUqreNDmOciIg0oQbL3d0LgVeBu80s0cyOAc4CZtYx/BngZjPrZWY9gZ8CMxoxr4iIhCHc79JfAyQAWcDzwDR3zzSzyWZWUGPc48CbwFJgGTCnepuIiDSjsM5zd/ccQuev194+l9BB1P33HfjP6puIiATEmujLowcWwiwb2HSQT+9K6FuzkSZSc0HkZlOuA6NcByYWc/Vz9zrPSImIcj8UZjbf3dODzlFbpOaCyM2mXAdGuQ5MS8ul9WtFRGKQyl1EJAbFQrk/EXSAekRqLojcbMp1YJTrwLSoXFE/5y4iIl8XC3vuIiJSi8pdRCQGqdxFRGJQzJW7mQ0xsxIzezboLABm9qyZ7TCzPDNbbWZXNvysJs/Uzsymm9kmM8s3s8VmdlrQuQDM7LrqpaBLzWxGwFk6m9lsMyus/lldEGSe6kwR8/OpKcLfUxH3GaypqTor5sqd0CUB5wUdoob7gP7ungycCdxrZuMCztQG2AIcD6QA/wW8ZGb9A8y033bgXuDJoIPw1ctLXgg8amZBX3wmkn4+NUXyeyoSP4M1NUlnxVS5m9n5wD7g/aCz7Ofume5euv9u9W1QgJFw90J3v8vdN7p7lbu/Rehat4G/4d39VXd/DdgTZI4DvLxks4mUn09tEf6eirjP4H5N2VkxU+5mlgzcDdwcdJbazOzPZlYErAR2AH8LONJXmFkaocspau39/3cgl5eUWiLtPRWJn8Gm7qyYKXfgHmC6u28NOkht7n4NocsSTia0Nn7pNz+j+ZhZHPAc8LS7rww6TwQ5kMtLSg2R+J6K0M9gk3ZWVJS7mX1oZl7P7RMzGwOcBDwYSblqjnX3yupf7XsD0yIhl5m1InTRlTLguqbMdCC5IsSBXF5SqjX3e+pANOdnsCHN0VlhreceNHf/1jc9bmY3Av2BzdXX4k4CWpvZCHc/Mqhc9WhDE8/3hZOr+qLl0wkdLDzd3cubMlO4uSLIvy8v6e5rqrfpspHfIIj31EFq8s9gGL5FE3dWVOy5h+EJQv+zxlTfHiN0FahTggxlZt3M7HwzSzKz1mZ2CvBDIuOA76PAcOAMdy8OOsx+ZtbGzOKB1oTe7PFm1uw7IQd4eclmEyk/n3pE3Hsqgj+DTd9Z7h5zN+Au4NkIyJEKfEToaHgeocsP/igCcvUjdMZACaHph/23CyMg2138/xkN+293BZSlM/AaUAhsBi7Qzye63lOR+hms5/9ro3aWFg4TEYlBsTItIyIiNajcRURikMpdRCQGqdxFRGKQyl1EJAap3EVEYpDKXUQkBqncRURi0P8BDYVAdlrTNlwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CEUFMyRN0EQ"
      },
      "source": [
        "Sigmoid function squeezes the values between the range 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoG0tkS_Omkl"
      },
      "source": [
        "# Updating our above mnist_loss with a sigmoid function \n",
        "def mnist_loss(predictions, targets):\n",
        "  return torch.where(targets == 1 , 1-predictions ,predictions).mean()"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJkuVbkXPnw8"
      },
      "source": [
        "metric --> For human understanding \n",
        "loss --> For automatic updation (machine's metric to improve the performance of our model)\n",
        "\n",
        "The loss function is calculated for each item in our dataset, and then at the end of an epoch, the loss values are all averaged and the overall mean is reported for the epoch.\n",
        "\n",
        "Metrics on other hand are the numbers we care about and these are the values which are printed at end of each epoch that tells us how our model is doing.\n",
        "\n",
        "\n",
        "### SGD and Mini-Batches \n",
        "\n",
        "Now in here we will try to automate most of the parts. \n",
        "\n",
        "- Batching a handful items into a seperate mini-batches and making computations on those mini-batches rather than computing on the whole dataset / items.\n",
        "-Choosing a good batch size is one of the decisions one need to make a deep learning practitioner to train the model quickly and accurately.\n",
        "- The important reason for having mini-batches is it could run on GPU, so the computations takes place even more faster. \n",
        "\n",
        "\n",
        "Before putting our data into batches, \n",
        "- We gotta randomly shuffle the data. \n",
        "\n",
        "\n",
        "- it prevents any bias during the training\n",
        "- it prevents the model from learning the order of the training\n",
        "- it helps the training converge fast\n",
        "\n",
        "https://stats.stackexchange.com/questions/245502/why-should-we-shuffle-data-while-training-a-neural-network\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-fC_h4zQB9K"
      },
      "source": [
        "#### DataLoader\n",
        "\n",
        "A `DataLoader` can take any Python collection and turn it into a iterator (generator) over many batches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWuKgzl7WUNx",
        "outputId": "1b47902e-12e3-4f43-dfcb-0353e7b5ddb7"
      },
      "source": [
        "# Sample DataLoader \n",
        "\n",
        "coll = range(20) \n",
        "dls = DataLoader(coll , batch_size = 5 , shuffle = True)\n",
        "list(dls)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 8,  2,  5, 12, 14]),\n",
              " tensor([ 7, 19, 17,  1, 18]),\n",
              " tensor([ 0, 16,  6, 13, 10]),\n",
              " tensor([11,  9, 15,  3,  4])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXmsaDI_WvG1"
      },
      "source": [
        "`Dataset` --> Contains collection of both independent and dependent variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKtlvhsTXArd",
        "outputId": "1c0277ff-a859-4440-9009-8b77a898f553"
      },
      "source": [
        "# Example of Dataset \n",
        "ds = L(enumerate(string.ascii_lowercase))\n",
        "ds"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxFDBstXKpK"
      },
      "source": [
        "In practice, we pass a `Dataset` to a `DataLoader` and it returns batches of independent and dependent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081C7xmRXZFh"
      },
      "source": [
        "### Putting it all together \n",
        "\n",
        "- Initialize the parameters \n",
        "- Making a prediction \n",
        "- Depending upon my prediction, will calculate my loss function.\n",
        "- Call our good friend gradients, activate the gradients of our weights. Gradients helps in updating the parameters.\n",
        "- We are going to perform to step, where we will multiply our learning with our weight gradients. \n",
        "- We will train this for our desired epochs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlhLm6EOY8g8"
      },
      "source": [
        "# re-initializing the parameters \n",
        "weights = init_params((28*28 , 1))\n",
        "bias = init_params(1)\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmmdglZWcqAe",
        "outputId": "f1420fee-0efe-43b2-ba90-90488d34eac9"
      },
      "source": [
        "# Constructing our DataLoader \n",
        "dl = DataLoader(dset , batch_size= 256)\n",
        "# Slicing off first mini-batch\n",
        "xb , yb = first(dl)\n",
        "\n",
        "# Checking the shape \n",
        "xb.shape , yb.shape"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GebvSZW6dTO_"
      },
      "source": [
        "# Doing the same for validaton set \n",
        "valid_dl = DataLoader(valid_dset , batch_size = 256)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOsVsZsMdg5H",
        "outputId": "f5475659-4d49-434c-f1bf-acde0a79e16e"
      },
      "source": [
        "# Create the mini-batch of size 4 \n",
        "batch = train_x[:4]\n",
        "batch.shape"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCK__wf0dsE-",
        "outputId": "bfc0cd9b-07b8-4f33-911e-bb174be9d7fe"
      },
      "source": [
        "# Making predictions on our sample batch \n",
        "preds = linear1(batch)\n",
        "preds\n"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -7.9686],\n",
              "        [ -5.4528],\n",
              "        [ -9.0583],\n",
              "        [-16.6391]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GunWe6ce_0A",
        "outputId": "8b44085b-e6a7-4506-82f6-6c9c93b3ad6d"
      },
      "source": [
        "# Labels \n",
        "train_y[:4]"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDK5ma6EdtQ-",
        "outputId": "7167ad1e-a441-4047-dfba-0fa31bfd9b84"
      },
      "source": [
        "# Calculating the loss \n",
        "loss = mnist_loss(preds , train_y[:4])\n",
        "loss "
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.7797, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avt9NCs8fHRJ",
        "outputId": "b2c83f17-2715-4874-f045-3d9fc6342281"
      },
      "source": [
        "# Now calculating the gradients \n",
        "loss.backward()\n",
        "print(f'Shape of weight calculated: {weights.grad.shape}')\n",
        "print(f'Turning into a single tensor: {weights.grad.mean()}')\n",
        "print(f'Bias: {bias.grad}')"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of weight calculated: torch.Size([784, 1])\n",
            "Turning into a single tensor: -0.15112045407295227\n",
            "Bias: tensor([-1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8786Y4q9ftRv"
      },
      "source": [
        "# Putting altogether in a function \n",
        "def calc_grad(xb , yb , model):\n",
        "  '''\n",
        "  xb --> mini-batched training set \n",
        "  yb --> mini-batched test set \n",
        "  model --> the model we want to use \n",
        "  '''\n",
        "  # Making a prediction \n",
        "  preds = model(xb) \n",
        "  # Calculating the loss\n",
        "  loss = mnist_loss(preds , yb)\n",
        "  # Activating the gradients (for updating our weights)\n",
        "  loss.backward() \n",
        "  \n"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRHr0Eykhd2G",
        "outputId": "84825f62-c0f2-4436-aabf-493023864ad7"
      },
      "source": [
        "# Testing the above function \n",
        "calc_grad(batch , train_y[:4] , linear1)\n",
        "\n",
        "# Below are the weights and biases after calculating the gradients above \n",
        "weights.grad.mean() , bias.grad"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.7438), tensor([-5.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdrwVulNhz1g",
        "outputId": "af991e26-124f-40ec-f335-74ecf8ccad79"
      },
      "source": [
        "# Calling it another time\n",
        "calc_grad(batch , train_y[:4] , linear1)\n",
        "\n",
        "# Below are wts and biases\n",
        "weights.grad.mean() , bias.grad"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.8949), tensor([-6.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9gtJ5AeiCgB",
        "outputId": "37de702c-2cb0-4343-f230-33feb8c44a80"
      },
      "source": [
        "# Making the gradients to zero, so it won't affect the previous computer gradients \n",
        "weights.grad.zero_()\n",
        "bias.grad.zero_()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c3E362GifK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e649c60-6bb4-4113-f536-2e402fcfc55e"
      },
      "source": [
        "# Now it won't add with the previous gradients (because we set it to zero)\n",
        "# Calling it another time\n",
        "calc_grad(batch , train_y[:4] , linear1)\n",
        "\n",
        "# Below are wts and biases\n",
        "weights.grad.mean() , bias.grad"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.1511), tensor([-1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddXL62BLctYP"
      },
      "source": [
        "Awesome! So we have one remaining step, that is to update the weights and biases (parameters) on the gradient and the learnin rate. \n",
        "\n",
        "We set the gradients to zero to avoid the confusion when we try to compute the derivative to the next batch. \n",
        "\n",
        "It's time now to calculate the accuracy, to decide if an output represent a 3 or 7,\n",
        "- if it's greater than 0, then it's 7 \n",
        "- if it's less than 0, then it's 3 \n",
        "\n",
        "Now the updated function trains a model with the learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GMmFdKhfmrS"
      },
      "source": [
        "# It will have a step function and runs for one epoch \n",
        "def train_epoch(model , lr , params):\n",
        "  # Training loop\n",
        "  for xb , yb in dl:\n",
        "    calc_grad(xb , yb , model)\n",
        "    for p in params:\n",
        "      p.data  -= p.grad*lr\n",
        "      p.grad.zero_()"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGFnMzNW1PLc"
      },
      "source": [
        "Important Links \n",
        "- https://discuss.pytorch.org/t/when-grad-is-none/4466\n",
        "- https://forums.fast.ai/t/autograd-does-not-appear-to-be-setting-gradient-lesson-4-04-mnist-basics-ipynb/82358"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y557GoFRtgT-"
      },
      "source": [
        "#train_epoch(linear1 , lr , params)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJAPuNi-g-1i",
        "outputId": "9648bb52-ac06-4d03-857d-aeed24d0308c"
      },
      "source": [
        "(preds > 0.0).float() == train_y[:4]"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWG_A0KGhC5Z"
      },
      "source": [
        "Now we are creating a function that would calculate the accuracy from our x and y data batches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nTIsMFniU2I"
      },
      "source": [
        "# Function to calculate the accuracy \n",
        "def batch_accuracy(xb , yb):\n",
        "  '''\n",
        "  xb --> input data with multiplied weights [model(xb)] \n",
        "  yb --> targets\n",
        "  '''\n",
        "  preds = xb.sigmoid()\n",
        "  # Returns True (or) False\n",
        "  correct = (preds > 0.5) == yb\n",
        "  # Converting into 0s and 1s\n",
        "  return correct.float().mean()"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFLvTxsci32n",
        "outputId": "c8d8e807-de6b-47d7-d68d-c1b14bd87bc7"
      },
      "source": [
        "# Using the above function we've made \n",
        "print(f'We got the accuracy of: {batch_accuracy(linear1(batch) , train_y[:4])}')"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We got the accuracy of: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KS4XP31jbNq"
      },
      "source": [
        "Great our function works, to make it more sense let's make our model to make predictions on a validation set and calculate accuracy from there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDw_WcE1jnjO"
      },
      "source": [
        "# Calculate accuracy on our validation set \n",
        "def validate_epoch(model):\n",
        "  '''\n",
        "  model --> Input your model (linear1)\n",
        "  This function will calculate the accuracy on a validation dataloader \n",
        "  '''\n",
        "  accs = [batch_accuracy(model(xb) , yb) for xb , yb in valid_dl]\n",
        "  return round(torch.stack(accs).mean().item() , 4)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEysM8eujpKu",
        "outputId": "84f768b7-11c9-444f-f86b-9b35cc3df481"
      },
      "source": [
        "ac = [batch_accuracy(linear1(batch) , train_y[:4]) for xb , yb in valid_dl]\n",
        "ac"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe9_qUU-ouCE",
        "outputId": "d9c861c6-e34f-4edf-9ca8-c28292987ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "round(torch.stack(ac).mean().item() , 4)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN0aMKNCoyLK",
        "outputId": "c40832a3-8373-4080-c6fa-e2dc9bca5df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testing the above function                                                         \n",
        "validate_epoch(linear1)\n"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSQWFfpNyhsQ",
        "outputId": "fb660cf1-32f0-4740-9383-c4e27c2986b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def init_params(size, variance=1.0): \n",
        "  return (torch.randn(size, dtype=torch.float)*variance).requires_grad_()\n",
        "\n",
        "weights = init_params(size = ((28*28) ,1))\n",
        "bias = init_params(1)\n",
        "weights.shape , bias.shape\n",
        "\n"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 1]), torch.Size([1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml3w3pyNzCcG",
        "outputId": "7ef910fd-4be2-4eca-ca4a-bd975d56b825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setting up the hyperparameters (testing for one epoch)\n",
        "params = weights,bias\n",
        "lr = 4e-3\n",
        "train_epoch(linear1 , lr , params)\n",
        "validate_epoch(linear1)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3809"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yme6ci1ryev",
        "outputId": "f76aa31c-ff77-46b7-ef8b-ac90d1ba4024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Using both functions and training our model for 10 epochs \n",
        "for i in range(10):\n",
        "  train_epoch(linear1 , lr , params)\n",
        "  print(f'The accuracy is: {validate_epoch(linear1)}\\n')"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is: 0.422\n",
            "\n",
            "The accuracy is: 0.4592\n",
            "\n",
            "The accuracy is: 0.5068\n",
            "\n",
            "The accuracy is: 0.5456\n",
            "\n",
            "The accuracy is: 0.5903\n",
            "\n",
            "The accuracy is: 0.6302\n",
            "\n",
            "The accuracy is: 0.6741\n",
            "\n",
            "The accuracy is: 0.6988\n",
            "\n",
            "The accuracy is: 0.7303\n",
            "\n",
            "The accuracy is: 0.7608\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NsfyRZms0e2"
      },
      "source": [
        "### Creating an Optimizer\n",
        "So now we will use the power of the optimizer and get rid of two steps that is, \n",
        "- Initializing the parameters \n",
        "- Calculating gradients \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDd7qhRW6Ljv"
      },
      "source": [
        "# Creating the parametes by using pytorch's module\n",
        "import torch \n",
        "linear_model = nn.Linear((28*28) , 1)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP63_zBt6XQu",
        "outputId": "02bbb0bc-db08-459b-a6a7-c538bc5f7659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Unpacking weights and biases \n",
        "w , b = linear_model.parameters()\n",
        "w.shape , b.shape"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 784]), torch.Size([1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpIWvszk6v5C",
        "outputId": "b885eabf-b311-4481-fca0-147ae3a02022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'For Pytorch model the weights are : {w.shape}')\n",
        "print(f'For Pytorch model the bias are :{b.shape}')\n",
        "\n",
        "print('-------------------------  --------------------------')\n",
        "\n",
        "print(f'For our model the weights are :{weights.shape}')\n",
        "print(f'For our model the weights are :{bias.shape}')"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Pytorch model the weights are : torch.Size([1, 784])\n",
            "For Pytorch model the bias are :torch.Size([1])\n",
            "-------------------------  --------------------------\n",
            "For our model the weights are :torch.Size([784, 1])\n",
            "For our model the weights are :torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucGcgRy39W2C"
      },
      "source": [
        "> Setting the `p.grad = None` is gonna return 0 because there is no Null or None in C ++. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmGjxrKZ7cdb"
      },
      "source": [
        "# Creating an SGD optimizer\n",
        "lr = 1.\n",
        "opt = torch.optim.SGD(params = linear_model.parameters() ,\n",
        "                      lr = lr)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRyVZQIY-bRW"
      },
      "source": [
        "def train_epoch(model):\n",
        "  for xb , yb in dl:\n",
        "    calc_grad(xb , yb , model)\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5_tHzEp-FnY"
      },
      "source": [
        "# Creating the train_model function \n",
        "def train_model(model , epochs):\n",
        "  for i in range(epochs):\n",
        "    train_epoch(model)\n",
        "    print(f'The accuracy is: {validate_epoch(model)}\\n')"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBtIFj7h-w7b",
        "outputId": "e2bbee43-35ca-4e02-ddae-348b73c58882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_model(linear_model , 20)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n",
            "The accuracy is: 0.9533\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KECDDPj-8GW"
      },
      "source": [
        "Awesome so far, we managed to automate some of the stuffs we have been doing with the help of Pytorch. \n",
        "\n",
        "Now to automate the training process we are going to use Fastai's `Learner` class (train_model) \n",
        "\n",
        "To create a `Learner` we need a `DataLoaders`, and the `DataLoaders` containts both train and validation Dataloader. \n",
        "\n",
        "- `DataLoader` --> Create batches of the data and shuffles it. \n",
        "- `DataLoaders` --> Combines two DataLoader into one whole. \n",
        "\n",
        "**`Learner`** takes, \n",
        "- a `DataLoaders`\n",
        "- the model \n",
        "- optimization function \n",
        "- Loss function \n",
        "- metrics \n",
        "\n",
        "Important Links:\n",
        "- https://forums.fast.ai/t/core-usage-of-datablock-and-dataloader/69051/2\n",
        "- https://forums.fast.ai/t/combining-dataloaders/79549\n",
        "- https://forums.fast.ai/t/custom-dataset-and-dataloader-for-learner/81408"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUJp9fRuA1KD"
      },
      "source": [
        "# Creating our DataLoaders \n",
        "dls = DataLoaders(dl , valid_dl)\n"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5mdvPAyBtjv"
      },
      "source": [
        "# Creating a learner \n",
        "learn = Learner(dls , \n",
        "                model = nn.Linear(28*28 , 1) , \n",
        "                opt_func = SGD, \n",
        "                loss_func = mnist_loss , \n",
        "                metrics = batch_accuracy)"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBGgeTMKCB0n",
        "outputId": "e765d83a-5ce6-48ed-aebf-74094a47dcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Now training our learner for 10 epochs \n",
        "lr = 1e-4\n",
        "learn.fit(10 , lr = lr)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.334221</td>\n",
              "      <td>0.483747</td>\n",
              "      <td>0.503435</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.311584</td>\n",
              "      <td>0.450115</td>\n",
              "      <td>0.558881</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.285445</td>\n",
              "      <td>0.416484</td>\n",
              "      <td>0.629539</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.257020</td>\n",
              "      <td>0.382852</td>\n",
              "      <td>0.710010</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.227277</td>\n",
              "      <td>0.349220</td>\n",
              "      <td>0.770363</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.196844</td>\n",
              "      <td>0.315589</td>\n",
              "      <td>0.820412</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.166073</td>\n",
              "      <td>0.281957</td>\n",
              "      <td>0.859666</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.135146</td>\n",
              "      <td>0.248325</td>\n",
              "      <td>0.889107</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.104149</td>\n",
              "      <td>0.214693</td>\n",
              "      <td>0.903337</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.073122</td>\n",
              "      <td>0.181062</td>\n",
              "      <td>0.919038</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtYimrlCLjt"
      },
      "source": [
        "### Adding a Non-linearity \n",
        "\n",
        "So far we've been dealing with a simple linear classifier, but now we need something a bit more flexible enough to learn patterns in a complex task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1IPFOi1DJFn"
      },
      "source": [
        "# Constructing a basic neural net \n",
        "def simple_net(xb):\n",
        "  # Linear function\n",
        "  res = xb@w1 + b1 \n",
        "  # Relu function\n",
        "  res = res.max(tensor(0.0))\n",
        "  # Linear function \n",
        "  res = res@w2 + b2\n",
        "  return res\n"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DltFAEhIDqza"
      },
      "source": [
        "# Now we gotta initialize the parameters \n",
        "w1 = init_params((28 * 28) , 30)\n",
        "w2 = init_params(30 , 1)\n",
        "b1 = init_params(30)\n",
        "b2 = init_params(1)"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wYrHlMmEBRU"
      },
      "source": [
        "In the above, `w1` has 30 output activations which means `w2` must have 30 input activations, so they match.\n",
        "\n",
        "The function `res.max(tensor(0.0))` is called as rectified linear unit, also known as `ReLU`. All it does is replace negative number with a zero. We can use it by `F.relu` in Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2tzlO0cESLS",
        "outputId": "a297bcc7-5811-4d3b-805c-119a47680fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Plotting a relu function \n",
        "plot_function(F.relu)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWpMX-FyGI4h"
      },
      "source": [
        "#### Why there is a need for non-linear layers? \n",
        "\n",
        "- There is no use of stacking up more linear layer on after another. \n",
        "- Non-linear layers enables neural nets to learn making conditional decisions for controlling the computational flow. \n",
        "\n",
        "Important Links: \n",
        "- https://medium.com/swlh/why-are-neural-nets-non-linear-a46756c2d67f\n",
        "- https://forums.fast.ai/t/linear-vs-non-linear/1854\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_MckN-M2TS"
      },
      "source": [
        "# Using Pytorch writing a simple_net function \n",
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28 , 30), \n",
        "    nn.ReLU(), \n",
        "    nn.Linear(30 , 1)\n",
        ")"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbq8OO9nNQWP"
      },
      "source": [
        "The three lines of code that we have here are known as layers. \n",
        "\n",
        "The first and third layer known as **linear layers** and the 2nd layer known as **nonlinearity (or) activation function**\n",
        "\n",
        "Since `nn.Sequential` is a module, we can peek in the parameters of all modules it contains.\n",
        "\n",
        "And its a deeper model than we trained on before, so we will lower the learning rate and use few more epochs to balance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFGeG2GNofN",
        "outputId": "b2403e12-1875-4aaa-c11b-56532a974902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Using our simple net model \n",
        "learn = Learner(dls , simple_net , \n",
        "                opt_func = Adam ,\n",
        "                loss_func = mnist_loss , \n",
        "                metrics = batch_accuracy)\n",
        "\n",
        "# Training for 20 epochs \n",
        "learn.fit(20 , 0.1)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.504416</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOgRUJV5Ow9g"
      },
      "source": [
        "About Deeper model\n",
        "\n",
        "For deeper model we don't need to use many parameters, it turns out that we can use smaller matrices, with more layers and get better results than we would get with larger matrices with just few layers.\n",
        "\n",
        "Neural network contains a lot of numbers, but they are only two types of numbers that are calculated and the parameters that these numbers are calculated from.\n",
        "\n",
        "**Activations**\n",
        "\n",
        "Numbers that are calculated both by linear and non - linearity.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "Numbers that are randomly initialized and optimized ( numbers that define the model).\n",
        "\n",
        "Part of becoming a good deep learning practitioner is getting used to the idea of looking at your activations and parameters, and plotting them and testing whether they are behaving correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SapImuH9S7yL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}