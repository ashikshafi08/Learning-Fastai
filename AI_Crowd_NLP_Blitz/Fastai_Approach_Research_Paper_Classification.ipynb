{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai_Approach_Research_Paper_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAX2TEGnuQld1rDUSUI1Q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning-Fastai/blob/main/AI_Crowd_NLP_Blitz/Fastai_Approach_Research_Paper_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rzaA0YCrkGA"
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_ynhPzgrr1a",
        "outputId": "e147131b-298f-4bf6-f3e3-f003e958c665"
      },
      "source": [
        "!pip install -q -U aicrowd-cli\n",
        "API_KEY = '' \n",
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 13.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 16.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnwKahOusAdW",
        "outputId": "8c4472d8-9b08-4a10-b0a3-9813243c1900"
      },
      "source": [
        "# Downloading the Dataset ( removing data and assets folder if existing already and then creating the folder )\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "!rm -rf assets\n",
        "!mkdir assets\n",
        "\n",
        "!aicrowd dataset download --challenge research-paper-classification -j 3 -o data # Downloading the dataset and saving it in data folder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rval.csv:   0% 0.00/883k [00:00<?, ?B/s]\n",
            "\rtest.csv:   0% 0.00/3.01M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\rtrain.csv:   0% 0.00/8.77M [00:00<?, ?B/s]\u001b[A\u001b[A\rval.csv: 100% 883k/883k [00:00<00:00, 6.45MB/s]\rval.csv: 100% 883k/883k [00:00<00:00, 6.44MB/s]\n",
            "\n",
            "\rtest.csv: 100% 3.01M/3.01M [00:00<00:00, 15.4MB/s]\u001b[A\rtest.csv: 100% 3.01M/3.01M [00:00<00:00, 15.4MB/s]\n",
            "\n",
            "\n",
            "\rtrain.csv: 100% 8.77M/8.77M [00:00<00:00, 34.9MB/s]\u001b[A\u001b[A\rtrain.csv: 100% 8.77M/8.77M [00:00<00:00, 34.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5QFGUpnsCu_",
        "outputId": "25008587-c0ca-4594-bd9a-ce7e8f60abeb"
      },
      "source": [
        "# Importing the needed packages\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text.all import * \n",
        "import pandas as pd \n",
        "print(fastai.__version__)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wPIvdIasLJe",
        "outputId": "9cd9ede7-21ff-49c0-cdde-da854718b6c0"
      },
      "source": [
        "# Importing the data \n",
        "\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "val_data = pd.read_csv('data/val.csv')\n",
        "test_data = pd.read_csv('data/test.csv')\n",
        "\n",
        "# Printing out all shapes of our data \n",
        "print(f'Shape of the train data: {train_data.shape}')\n",
        "print(f'Shape of the validation data: {val_data.shape}')\n",
        "print(f'Shape of the test data: {test_data.shape}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train data: (31500, 3)\n",
            "Shape of the validation data: (2700, 3)\n",
            "Shape of the test data: (10800, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlw4YWO-sNRJ"
      },
      "source": [
        "data = pd.concat([train_data , val_data] , axis = 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XWOZ8GfsQHL",
        "outputId": "36137cd0-f522-4334-f09d-449d74f2fe16"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       0\n",
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6rufBK-sTEA"
      },
      "source": [
        "# Creating a DataBlock \n",
        "db = DataBlock(blocks = (TextBlock.from_df('text') , CategoryBlock) , \n",
        "               get_x = ColReader('text') , \n",
        "               get_y = ColReader('label') , \n",
        "               splitter = RandomSplitter(0.1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "-s2dk9Qis9Zv",
        "outputId": "1a5f6017-5165-4c00-8796-a5eec99f7099"
      },
      "source": [
        "# DataLoaders \n",
        "dls = db.dataloaders(data , bs =32)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "QLUzjxkKtAMp",
        "outputId": "ee1bd855-f719-4c91-9065-1b8cb7bd7674"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos despite over the years its main focus has been the support of processes in highly controlled domains , many domains of interest to the xxup xxunk community are characterized by ever - changing requirements , unpredictable environments and increasing amounts of data that influence the execution of process instances . xxup ai has concentrated its efforts on investigating dynamic domains that involve active control of computational entities and physical devices ( e.g. , robots , software agents , etc . ) in this context , xxmaj automated xxmaj planning , which is one of the oldest areas in xxup ai , is conceived as</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos in the first optimization , we compute the xxmaj center of xxmaj mass ( com ) trajectory , foot step locations , and introduce xxunk variables to account for violating the imposed constraints on the xxmaj zero xxmaj moment xxmaj point ( zmp ) the second optimization , in which we calculate the optimal external force that compensates for the xxup zmp tracking error . once contact is created , the xxup xxunk reduces to a single xxmaj quadratic xxmaj program ( qp ) that can be solved in real - time ( $ $ xxunk ) .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos . xxmaj class imbalance is a common problem in real - world object detection and classification tasks . xxmaj data of some classes is abundant making them an over - represented majority , and data of others is scarce . xxmaj this imbalance makes it challenging for classifiers to appropriately learn the discriminating boundaries of the majority and minority classes . xxmaj the proposed approach is applicable to both binary and multi - class problems without any modification . xxmaj moreover , as opposed to data level approaches , we do not alter the original data distribution</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxbos and relation prediction , respectively . xxmaj to achieve these goals , we propose a novel recurrent neural network model , called xxmaj hierarchical long - term xxmaj memory ( h - lstm ) . xxmaj it contains two coupled sub - networks : the xxmaj pixel ( p - ltm ) , and the xxmaj multi - scale xxmaj super - pixel ( ms - xxunk ) . xxmaj the model is capable of parsing scene geometric structures and outperforming several state - of - the - art methods by large margins</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxbos to learn a causal structure via interaction and learning . xxmaj we test our method over two different scenarios , and the results presented for the first test scenario demonstrate the usefulness of our technique to learning an effective action . xxmaj on the other hand , the second experiment , shows that our proposal manages to understand the underlying cause of several tasks with different sizes and different causal structures . a xxmaj random xxmaj graph is an random object which take its values in the space of graphs .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxbos the emergence or bootstrap of a lexicon involves the repeated interaction between at least two agents who must reach a consensus on how to name n objects using h words . here we consider minimal models of two types of learning algorithms : cross - situational learning , in which the individuals determine the meaning of the word by looking for something in common across all observed uses of that word . we show that they yield the same communication accuracy in the realistic limits of large n and h .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xxbos and the post - classification pipeline perform classification on each video snippet and then aggregate the classification scores to obtain the video - level classification score . xxmaj moreover , we discover that an ideal classifier may possess two characteristics : 1 ) xxmaj the frame level classification results obtained from the pre - classification stream should be consistent ; 3 ) xxmaj the class results of these two streams should not be identical . xxmaj this achieves the novel xxmaj equivalent xxmaj classification xxmaj mapping ( xxunk ) mechanism .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxbos video - based person re - identification ( re - id ) aims at matching the same person across video clips . in this paper , we propose a hybrid framework , xxmaj dense xxmaj interaction xxmaj learning ( xxunk ) , that takes the principal advantages of both cnn - based and xxmaj attention - based architectures . we introduce spatio - temporal positional xxmaj embedding ( step - xxunk ) into the xxup di decoder to investigate the positional relation among the spatial - temporal inputs .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xxbos management in the airline scheduling process can be xxunk into proactive and reactive processes depending upon the time of schedule execution . xxmaj this paper introduces an uncertainty transfer function model ( xxunk ) framework that characterizes uncertainty for proactive airline disruption management before scheduling execution , reactive airline xxunk management during scheduling , and proactive airlines after scheduling executed . we use historical xxmaj markov models ( a special class of probabilistic graphical models ) that can efficiently perform pattern learning and inference on portions of large data</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUsb2W3cw2pE"
      },
      "source": [
        "f1_score = F1Score(average = 'weighted')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni0BwSSytCbm",
        "outputId": "fb673735-a46a-4fb4-c3aa-98b9384f1687"
      },
      "source": [
        "learn = text_classifier_learner(dls, AWD_LSTM, metrics=[accuracy , f1_score] , drop_mult= 0.4 , wd = 0.4 ,seq_len= 128)\n",
        "learn"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.text.learner.TextLearner at 0x7f4b618178d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "pEGart5itTzP",
        "outputId": "6c9bc68c-8a0d-4e54-a102-9b7afe91aab9"
      },
      "source": [
        "learn.fine_tune(10 , 2e-2 , lr_mult = 125 , pct_start= 0.4)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.834396</td>\n",
              "      <td>0.767437</td>\n",
              "      <td>0.706140</td>\n",
              "      <td>0.704514</td>\n",
              "      <td>00:47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.532614</td>\n",
              "      <td>0.550512</td>\n",
              "      <td>0.786550</td>\n",
              "      <td>0.790050</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.487497</td>\n",
              "      <td>0.563081</td>\n",
              "      <td>0.801754</td>\n",
              "      <td>0.794954</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.463845</td>\n",
              "      <td>0.456923</td>\n",
              "      <td>0.833626</td>\n",
              "      <td>0.822568</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.455221</td>\n",
              "      <td>0.448122</td>\n",
              "      <td>0.836257</td>\n",
              "      <td>0.834150</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.392752</td>\n",
              "      <td>0.491956</td>\n",
              "      <td>0.828070</td>\n",
              "      <td>0.826328</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.355973</td>\n",
              "      <td>0.425789</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.853493</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.281772</td>\n",
              "      <td>0.449395</td>\n",
              "      <td>0.847368</td>\n",
              "      <td>0.850680</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.233548</td>\n",
              "      <td>0.502182</td>\n",
              "      <td>0.851170</td>\n",
              "      <td>0.843596</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.166698</td>\n",
              "      <td>0.494890</td>\n",
              "      <td>0.852339</td>\n",
              "      <td>0.848096</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.144732</td>\n",
              "      <td>0.508216</td>\n",
              "      <td>0.857895</td>\n",
              "      <td>0.857413</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "i9zBy8TAvUwd",
        "outputId": "9baabc25-eb9c-49db-ea9f-d8e64448015f"
      },
      "source": [
        "test_data.drop('label' , inplace = True , axis = 1)\n",
        "test_data.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect iris presentation attacks by extracting multiple micro-stripes of expanded normalized iris textures . in this procedure, the segmented area is processed to provide lower dimensional input segments and a higher number of learning samples .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solution to SLAM for map update in terms of efficiency, cost, availability, and map reuse . a virtual LIDAR that estimates the depth of objects in the 3D map is used to generate a compact point cloud .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT features of color segmented slice regions of an ear . proposed method makes use of Gaussian mixture model (GMM) to build ear model using vector quantization algorithm and K-L divergence .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional trajectory of a moving instance of an object category using stereo video data . we track the two-dimensional shape of objects on pixel level .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating run time penalties . both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                                                                                                                                                                                                                                                                                                                            text\n",
              "0   0                                                     we propose a lightweight framework to detect iris presentation attacks by extracting multiple micro-stripes of expanded normalized iris textures . in this procedure, the segmented area is processed to provide lower dimensional input segments and a higher number of learning samples .\n",
              "1   1                                                                                             the proposed method presents an alternate solution to SLAM for map update in terms of efficiency, cost, availability, and map reuse . a virtual LIDAR that estimates the depth of objects in the 3D map is used to generate a compact point cloud .\n",
              "2   2                                                                                                      proposed ear identification method fusing SIFT features of color segmented slice regions of an ear . proposed method makes use of Gaussian mixture model (GMM) to build ear model using vector quantization algorithm and K-L divergence .\n",
              "3   3                                                                                                                                                    a method to reconstruct the three-dimensional trajectory of a moving instance of an object category using stereo video data . we track the two-dimensional shape of objects on pixel level .\n",
              "4   4  strong local consistencies can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating run time penalties . both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f3xTlFXytW_p",
        "outputId": "afe1927b-75de-4fe2-b9f3-815e2e8b266a"
      },
      "source": [
        "test_dl = learn.dls.test_dl(test_data)\n",
        "preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "ZeyV0Q2HvMed",
        "outputId": "72ba40d5-078f-4a0e-e0a4-5349f3bd0909"
      },
      "source": [
        "test_data['label'] = preds[0].argmax(dim = 1)\n",
        "test_data.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect iris presentation attacks by extracting multiple micro-stripes of expanded normalized iris textures . in this procedure, the segmented area is processed to provide lower dimensional input segments and a higher number of learning samples .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solution to SLAM for map update in terms of efficiency, cost, availability, and map reuse . a virtual LIDAR that estimates the depth of objects in the 3D map is used to generate a compact point cloud .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT features of color segmented slice regions of an ear . proposed method makes use of Gaussian mixture model (GMM) to build ear model using vector quantization algorithm and K-L divergence .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional trajectory of a moving instance of an object category using stereo video data . we track the two-dimensional shape of objects on pixel level .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating run time penalties . both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     3\n",
              "1   1  ...     2\n",
              "2   2  ...     3\n",
              "3   3  ...     3\n",
              "4   4  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jtzbEtXvNmr"
      },
      "source": [
        "import os\n",
        "#!mkdir assets\n",
        "test_data.to_csv(os.path.join(\"assets\", \"submission.csv\"), index=False)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULPt_5iJwEWF",
        "outputId": "832e1985-23dc-4c98-9294-cf1013130065"
      },
      "source": [
        "!aicrowd notebook submit -c research-paper-classification -a assets --no-verify"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using notebook: /content/drive/MyDrive/Colab Notebooks/Fastai_Approach_Research_Paper_Classification.ipynb for submission...\n",
            "Removing existing files from submission directory...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m1.1/1.1 MB\u001b[0m • \u001b[31m1.2 MB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                                        ╭─────────────────────────╮                                                        \n",
            "                                                        │ \u001b[1mSuccessfully submitted!\u001b[0m │                                                        \n",
            "                                                        ╰─────────────────────────╯                                                        \n",
            "\u001b[3m                                                              Important links                                                              \u001b[0m\n",
            "┌──────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│  This submission │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions/146841              │\n",
            "│                  │                                                                                                                      │\n",
            "│  All submissions │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions?my_submissions=true │\n",
            "│                  │                                                                                                                      │\n",
            "│      Leaderboard │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/leaderboards                    │\n",
            "│                  │                                                                                                                      │\n",
            "│ Discussion forum │ https://discourse.aicrowd.com/c/ai-blitz-9                                                                           │\n",
            "│                  │                                                                                                                      │\n",
            "│   Challenge page │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification                                 │\n",
            "└──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmYOL1-vwFUw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}